{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile as tif, numpy as np, os, matplotlib.pyplot as plt, sys, pandas as pd\n",
    "import shutil, itertools \n",
    "from collections import Counter\n",
    "import datetime\n",
    "from subprocess import check_output\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/net/birdstore/Active_Atlas_Data/data_root/pipeline_data/DK52/preps/'\n",
    "filename = 'DK52_beth_COMs_new.pkl'\n",
    "inpath = os.path.join(filepath, filename)\n",
    "outpath = os.path.join(filepath, 'points.pts')\n",
    "d = pd.read_pickle(inpath)\n",
    "point_dict = dict(sorted(d.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for structure, points in point_dict.items():\n",
    "    x = float(points[0])\n",
    "    y = float(points[1])\n",
    "    xs = x/16\n",
    "    ys = y/16\n",
    "    z = points[2]\n",
    "    if 'SC' in structure:\n",
    "        print(structure, points, x,y,z, xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outpath, 'w') as f:\n",
    "    f.write('point\\n')\n",
    "    f.write(f'{len(point_dict)}\\n')\n",
    "    for structure, points in point_dict.items():\n",
    "        x = points[0]/64\n",
    "        y = points[1]/64\n",
    "        z = points[2]\n",
    "        #print(structure, points, x,y,z)\n",
    "        f.write(f'{x} {y} {z}')\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_or_index = 'OutputPoint'\n",
    "inpath = os.path.join(filepath, 'CH1', 'registered', 'outputpoints.txt')\n",
    "with open(inpath, \"r\") as f:                \n",
    "    lines=f.readlines()\n",
    "    f.close()\n",
    "assert len(lines) == len(point_dict)\n",
    "print(\"\\n\\n{} points detected\\n\\n\".format(len(lines)))\n",
    "for k, i in zip(point_dict.keys(), range(len(lines))):        \n",
    "    lx=lines[i].split()[lines[i].split().index(point_or_index)+3:lines[i].split().index(point_or_index)+6] #x,y,z\n",
    "    lf = [float(x) for x in lx]\n",
    "    print(k, lf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_transformix(pretransform_text_file, transformfile, dst):\n",
    "    \"\"\"apply elastix transform to points      \n",
    "    Inputs\n",
    "    -------------\n",
    "    pretransform_text_file = list of points that already have resizing transform\n",
    "    transformfile = elastix transform file\n",
    "    dst = folder\n",
    "    \n",
    "    Returns\n",
    "    ---------------\n",
    "    trnsfrm_out_file = pth to file containing post transformix points\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"Make sure elastix module is loaded!!!\")\n",
    "    sys.stdout.write(\"\\n***********Starting Transformix***********\")\n",
    "    #set paths    \n",
    "    trnsfrm_out_file = os.path.join(dst, \"outputpoints.txt\")\n",
    "    #run transformix point transform\n",
    "    call = \"transformix -def {} -out {} -tp {}\".format(pretransform_text_file, dst, transformfile)\n",
    "    print(check_output(call, shell=True))\n",
    "    sys.stdout.write(\"\\n   Transformix File Generated: {}\".format(trnsfrm_out_file)); sys.stdout.flush()\n",
    "    return trnsfrm_out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_file_for_elastix(src, dst):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    ---------\n",
    "    src = numpy file consiting of nx3 (ZYX points)\n",
    "    dst = folder location to write points\n",
    "    \"\"\"\n",
    "    print(\"This function assumes ZYX centers...\")\n",
    "    #setup folder\n",
    "    if not os.path.exists(dst): os.mkdir(dst)\n",
    "    #create txt file, with elastix header, then populate points\n",
    "    pth=os.path.join(dst, \"zyx_points_pretransform.txt\")\n",
    "    #load\n",
    "    \n",
    "    if type(src) == np.ndarray:\n",
    "        arr = src\n",
    "    else:\n",
    "        print(\"src param must be a numpy array\")\n",
    "\n",
    "    #convert\n",
    "    stringtowrite = \"\\n\".join([\"\\n\".join([\"{} {} {}\".format(i[2], i[1], i[0])]) for i in arr]) ####this step converts from zyx to xyz*****\n",
    "    #write file\n",
    "    sys.stdout.write(\"writing centers to transfomix input points text file...\"); sys.stdout.flush()\n",
    "    with open(pth, \"w+\") as fl:\n",
    "        fl.write(\"index\\n{}\\n\".format(len(arr)))    \n",
    "        fl.write(stringtowrite)\n",
    "        fl.close()\n",
    "    sys.stdout.write(\"...done writing centers\\n\"); sys.stdout.flush()\n",
    "    return pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not used in this script, but can unpack the .txt post-transformed points\n",
    "def unpack_pnts(points_file, dst=None):\n",
    "    \"\"\"\n",
    "    function to take elastix point transform file and return anatomical locations of those points\n",
    "    \n",
    "    Here elastix uses the xyz convention rather than the zyx numpy convention\n",
    "    \n",
    "    Inputs\n",
    "    -----------\n",
    "    points_file = post_transformed file, XYZ\n",
    "    \n",
    "    Returns\n",
    "    -----------\n",
    "    dst_fl = path to numpy array, ZYX\n",
    "    \n",
    "    \"\"\"   \n",
    "    #####inputs \n",
    "    assert type(points_file)==str\n",
    "    point_or_index = 'OutputPoint'\n",
    "    #get points\n",
    "    with open(points_file, \"r\") as f:                \n",
    "        lines=f.readlines()\n",
    "        f.close()\n",
    "    #####populate post-transformed array of contour centers\n",
    "    sys.stdout.write(\"\\n\\n{} points detected\\n\\n\".format(len(lines)))\n",
    "    #arr=np.empty((len(lines), 3))    \n",
    "    for i in range(len(lines)):        \n",
    "        #arr[i,...]=lines[i].split()[lines[i].split().index(point_or_index)+3:lines[i].split().index(point_or_index)+6] #x,y,z            \n",
    "        lx=lines[i].split()[lines[i].split().index(point_or_index)+3:lines[i].split().index(point_or_index)+6] #x,y,z\n",
    "        print(lx)\n",
    "    #optional save out of points\n",
    "    #dst_fl = os.path.join(dst, \"posttransformed_zyx_voxels.npy\")\n",
    "    #np.save(dst_fl, np.asarray([(z,y,x) for x,y,z in arr]))    \n",
    "    #check to see if any points where found\n",
    "    #print(\"output array shape {}\".format(arr.shape))   \n",
    "    #return dst_fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfile = '/net/birdstore/Active_Atlas_Data/data_root/pipeline_data/DK52/preps/transformix_output/outputpoints.txt'\n",
    "unpack_pnts(pfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to path where points are stored. This script is designed for pnts to be a numpy array of coordinates\n",
    "#in xyz orientation \n",
    "pnts = None #load in numpy array of xyz points\n",
    "\n",
    "#For resizing dimensions. We use the dimensions of the downsized volume that's created as part of \n",
    "#our processing pipeline to downsize the points\n",
    "downsized = None #path to downsized volume\n",
    "downsized = tif.imread(downsized) #sagittal\n",
    "zd,yd,xd = downsized.shape #sagittal (numpy's .shape returns the dimensions in z,y,x format)\n",
    "\n",
    "#reorient pnts to be in zyx format used for elastix\n",
    "pnts_sag = np.array([[xx[2],xx[1],xx[0]] for xx in pnts])\n",
    "\n",
    "#We use the dimensions of the fullsize volume to find the downsizing factor \n",
    "stitched = None #path to fullsize planes\n",
    "y,z = tif.imread(os.listdir(stitched)[0]).shape #sagittal, reading in shape of first plane\n",
    "x = len([xx for xx in os.listdir(stitched) if \".tif\" in xx]) #sagittal, number of planes\n",
    "#Downsizing factor \n",
    "f = ((zd/z),(yd/y),(xd/x))\n",
    "downsized_pnts_sag = np.array([[xx[0]*f[0],xx[1]*f[1],xx[2]*f[2]] for xx in pnts_sag]).astype(int)\n",
    "            \n",
    "#transform\n",
    "#make into transformix-friendly text file\n",
    "transformed_dst = None #path to where you want the transformed points to be outputted\n",
    "#Creates text file out of points array to be used for elastix\n",
    "pretransform_text_file = create_text_file_for_elastix(downsized_pnts_sag, transformed_dst)\n",
    "\n",
    "#This script assumes elastix has been to obtain transformation parameters\n",
    "#for the downsized volume -> Allen atlas\n",
    "elastix_dir = None #path to outputs of elastix transformation for downsized_volume -> Allen atlas\n",
    "#The TransformParameters.1.txt file that's outputted by elastix includes both the affine and\n",
    "#non affine transformations\n",
    "transformfile = os.path.join(elastix_dir, \"TransformParameters.1.txt\")\n",
    "\n",
    "#run transformix on points\n",
    "points_file = point_transformix(pretransform_text_file, transformfile, transformed_dst)\n",
    "#Points_file is a .txt file of transformed points. The unpack_pnts function can be modified to read in this\n",
    "#file into an array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
