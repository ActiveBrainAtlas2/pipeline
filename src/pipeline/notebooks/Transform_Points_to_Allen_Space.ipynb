{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile as tif, numpy as np, os, matplotlib.pyplot as plt, sys, pandas as pd\n",
    "import shutil, itertools \n",
    "from collections import Counter\n",
    "import datetime\n",
    "from subprocess import check_output\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/net/birdstore/Active_Atlas_Data/data_root/pipeline_data/DK52/preps/'\n",
    "filename = 'DK52_beth_COMs_new.pkl'\n",
    "inpath = os.path.join(filepath, filename)\n",
    "outpath = os.path.join(filepath, 'points.pts')\n",
    "d = pd.read_pickle(inpath)\n",
    "point_dict = dict(sorted(d.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SC [33868, 9061, 222] 33868.0 9061.0 222 2116.75 566.3125\n"
     ]
    }
   ],
   "source": [
    "for structure, points in point_dict.items():\n",
    "    x = float(points[0])\n",
    "    y = float(points[1])\n",
    "    xs = x/16\n",
    "    ys = y/16\n",
    "    z = points[2]\n",
    "    if 'SC' in structure:\n",
    "        print(structure, points, x,y,z, xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outpath, 'w') as f:\n",
    "    f.write('point\\n')\n",
    "    f.write(f'{len(point_dict)}\\n')\n",
    "    for structure, points in point_dict.items():\n",
    "        x = points[0]/64\n",
    "        y = points[1]/64\n",
    "        z = points[2]\n",
    "        #print(structure, points, x,y,z)\n",
    "        f.write(f'{x} {y} {z}')\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "47 points detected\n",
      "\n",
      "\n",
      "10N_L [500.512221, 248.691338, 257.374289]\n",
      "10N_R [501.696478, 252.18094, 283.184052]\n",
      "12N [499.868243, 268.598859, 270.123122]\n",
      "3N_L [366.15132, 165.807747, 271.609204]\n",
      "3N_R [365.113073, 164.242276, 285.997507]\n",
      "4N_L [370.593154, 165.657649, 261.089673]\n",
      "4N_R [366.658047, 165.45432, 289.456491]\n",
      "5N_L [410.312028, 234.372111, 216.766187]\n",
      "5N_R [405.93558, 235.021204, 330.595176]\n",
      "6N_L [423.51415, 261.855487, 255.217104]\n",
      "6N_R [422.552603, 260.584619, 297.371374]\n",
      "7N_L [440.274849, 312.526827, 204.99868]\n",
      "7N_R [451.480947, 312.761586, 343.031501]\n",
      "7n_L [423.854287, 269.362047, 223.75192]\n",
      "7n_R [425.850583, 271.567117, 330.232982]\n",
      "AP [510.188587, 236.036024, 268.278722]\n",
      "Amb_L [480.181819, 310.156858, 201.457879]\n",
      "Amb_R [484.395068, 311.078001, 332.139022]\n",
      "DC_L [472.570263, 223.8321, 172.565751]\n",
      "DC_R [481.990043, 225.930831, 361.948401]\n",
      "IC [430.064034, 82.104129, 265.310619]\n",
      "LC_L [429.331468, 208.248984, 226.434939]\n",
      "LC_R [421.246766, 201.576447, 315.818351]\n",
      "LRt_L [532.397766, 321.775277, 216.047824]\n",
      "LRt_R [533.081503, 324.988036, 316.226833]\n",
      "PBG_L [382.713776, 162.38173, 203.354084]\n",
      "PBG_R [370.405597, 161.760006, 331.980485]\n",
      "Pn_L [355.423751, 269.890917, 247.387303]\n",
      "Pn_R [381.913386, 272.531751, 308.600966]\n",
      "RtTg [376.552688, 249.509036, 281.792808]\n",
      "SC [386.919377, 76.704191, 264.416641]\n",
      "SNC_L [347.802739, 234.554292, 211.662163]\n",
      "SNC_R [369.55438, 202.52753, 323.876615]\n",
      "SNR_L [357.676601, 218.98796, 206.259255]\n",
      "SNR_R [374.26706, 212.408898, 322.777186]\n",
      "SP5I_L [503.877392, 274.835214, 200.981176]\n",
      "SP5I_R [513.051145, 283.963151, 340.00674]\n",
      "Sp5I_L [485.819107, 272.473678, 194.402345]\n",
      "Sp5I_R [490.499806, 287.577908, 337.628747]\n",
      "Tz_L [383.999581, 296.420789, 255.055319]\n",
      "Tz_R [389.583294, 303.062299, 309.91601]\n",
      "VCA_L [444.900359, 240.203207, 167.726746]\n",
      "VCA_R [452.366712, 232.233829, 369.410334]\n",
      "VCP_L [464.338721, 263.393033, 163.891103]\n",
      "VCP_R [477.468653, 273.006913, 367.244555]\n",
      "VLL_L [372.979936, 230.514693, 210.206167]\n",
      "VLL_R [390.023427, 235.222999, 328.401605]\n"
     ]
    }
   ],
   "source": [
    "point_or_index = 'OutputPoint'\n",
    "inpath = os.path.join(filepath, 'CH1', 'registered', 'outputpoints.txt')\n",
    "with open(inpath, \"r\") as f:                \n",
    "    lines=f.readlines()\n",
    "    f.close()\n",
    "assert len(lines) == len(point_dict)\n",
    "print(\"\\n\\n{} points detected\\n\\n\".format(len(lines)))\n",
    "for k, i in zip(point_dict.keys(), range(len(lines))):        \n",
    "    lx=lines[i].split()[lines[i].split().index(point_or_index)+3:lines[i].split().index(point_or_index)+6] #x,y,z\n",
    "    lf = [float(x) for x in lx]\n",
    "    print(k, lf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_transformix(pretransform_text_file, transformfile, dst):\n",
    "    \"\"\"apply elastix transform to points      \n",
    "    Inputs\n",
    "    -------------\n",
    "    pretransform_text_file = list of points that already have resizing transform\n",
    "    transformfile = elastix transform file\n",
    "    dst = folder\n",
    "    \n",
    "    Returns\n",
    "    ---------------\n",
    "    trnsfrm_out_file = pth to file containing post transformix points\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"Make sure elastix module is loaded!!!\")\n",
    "    sys.stdout.write(\"\\n***********Starting Transformix***********\")\n",
    "    #set paths    \n",
    "    trnsfrm_out_file = os.path.join(dst, \"outputpoints.txt\")\n",
    "    #run transformix point transform\n",
    "    call = \"transformix -def {} -out {} -tp {}\".format(pretransform_text_file, dst, transformfile)\n",
    "    print(check_output(call, shell=True))\n",
    "    sys.stdout.write(\"\\n   Transformix File Generated: {}\".format(trnsfrm_out_file)); sys.stdout.flush()\n",
    "    return trnsfrm_out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_file_for_elastix(src, dst):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    ---------\n",
    "    src = numpy file consiting of nx3 (ZYX points)\n",
    "    dst = folder location to write points\n",
    "    \"\"\"\n",
    "    print(\"This function assumes ZYX centers...\")\n",
    "    #setup folder\n",
    "    if not os.path.exists(dst): os.mkdir(dst)\n",
    "    #create txt file, with elastix header, then populate points\n",
    "    pth=os.path.join(dst, \"zyx_points_pretransform.txt\")\n",
    "    #load\n",
    "    \n",
    "    if type(src) == np.ndarray:\n",
    "        arr = src\n",
    "    else:\n",
    "        print(\"src param must be a numpy array\")\n",
    "\n",
    "    #convert\n",
    "    stringtowrite = \"\\n\".join([\"\\n\".join([\"{} {} {}\".format(i[2], i[1], i[0])]) for i in arr]) ####this step converts from zyx to xyz*****\n",
    "    #write file\n",
    "    sys.stdout.write(\"writing centers to transfomix input points text file...\"); sys.stdout.flush()\n",
    "    with open(pth, \"w+\") as fl:\n",
    "        fl.write(\"index\\n{}\\n\".format(len(arr)))    \n",
    "        fl.write(stringtowrite)\n",
    "        fl.close()\n",
    "    sys.stdout.write(\"...done writing centers\\n\"); sys.stdout.flush()\n",
    "    return pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not used in this script, but can unpack the .txt post-transformed points\n",
    "def unpack_pnts(points_file, dst=None):\n",
    "    \"\"\"\n",
    "    function to take elastix point transform file and return anatomical locations of those points\n",
    "    \n",
    "    Here elastix uses the xyz convention rather than the zyx numpy convention\n",
    "    \n",
    "    Inputs\n",
    "    -----------\n",
    "    points_file = post_transformed file, XYZ\n",
    "    \n",
    "    Returns\n",
    "    -----------\n",
    "    dst_fl = path to numpy array, ZYX\n",
    "    \n",
    "    \"\"\"   \n",
    "    #####inputs \n",
    "    assert type(points_file)==str\n",
    "    point_or_index = 'OutputPoint'\n",
    "    #get points\n",
    "    with open(points_file, \"r\") as f:                \n",
    "        lines=f.readlines()\n",
    "        f.close()\n",
    "    #####populate post-transformed array of contour centers\n",
    "    sys.stdout.write(\"\\n\\n{} points detected\\n\\n\".format(len(lines)))\n",
    "    #arr=np.empty((len(lines), 3))    \n",
    "    for i in range(len(lines)):        \n",
    "        #arr[i,...]=lines[i].split()[lines[i].split().index(point_or_index)+3:lines[i].split().index(point_or_index)+6] #x,y,z            \n",
    "        lx=lines[i].split()[lines[i].split().index(point_or_index)+3:lines[i].split().index(point_or_index)+6] #x,y,z\n",
    "        print(lx)\n",
    "    #optional save out of points\n",
    "    #dst_fl = os.path.join(dst, \"posttransformed_zyx_voxels.npy\")\n",
    "    #np.save(dst_fl, np.asarray([(z,y,x) for x,y,z in arr]))    \n",
    "    #check to see if any points where found\n",
    "    #print(\"output array shape {}\".format(arr.shape))   \n",
    "    #return dst_fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfile = '/net/birdstore/Active_Atlas_Data/data_root/pipeline_data/DK52/preps/transformix_output/outputpoints.txt'\n",
    "unpack_pnts(pfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to path where points are stored. This script is designed for pnts to be a numpy array of coordinates\n",
    "#in xyz orientation \n",
    "pnts = None #load in numpy array of xyz points\n",
    "\n",
    "#For resizing dimensions. We use the dimensions of the downsized volume that's created as part of \n",
    "#our processing pipeline to downsize the points\n",
    "downsized = None #path to downsized volume\n",
    "downsized = tif.imread(downsized) #sagittal\n",
    "zd,yd,xd = downsized.shape #sagittal (numpy's .shape returns the dimensions in z,y,x format)\n",
    "\n",
    "#reorient pnts to be in zyx format used for elastix\n",
    "pnts_sag = np.array([[xx[2],xx[1],xx[0]] for xx in pnts])\n",
    "\n",
    "#We use the dimensions of the fullsize volume to find the downsizing factor \n",
    "stitched = None #path to fullsize planes\n",
    "y,z = tif.imread(os.listdir(stitched)[0]).shape #sagittal, reading in shape of first plane\n",
    "x = len([xx for xx in os.listdir(stitched) if \".tif\" in xx]) #sagittal, number of planes\n",
    "#Downsizing factor \n",
    "f = ((zd/z),(yd/y),(xd/x))\n",
    "downsized_pnts_sag = np.array([[xx[0]*f[0],xx[1]*f[1],xx[2]*f[2]] for xx in pnts_sag]).astype(int)\n",
    "            \n",
    "#transform\n",
    "#make into transformix-friendly text file\n",
    "transformed_dst = None #path to where you want the transformed points to be outputted\n",
    "#Creates text file out of points array to be used for elastix\n",
    "pretransform_text_file = create_text_file_for_elastix(downsized_pnts_sag, transformed_dst)\n",
    "\n",
    "#This script assumes elastix has been to obtain transformation parameters\n",
    "#for the downsized volume -> Allen atlas\n",
    "elastix_dir = None #path to outputs of elastix transformation for downsized_volume -> Allen atlas\n",
    "#The TransformParameters.1.txt file that's outputted by elastix includes both the affine and\n",
    "#non affine transformations\n",
    "transformfile = os.path.join(elastix_dir, \"TransformParameters.1.txt\")\n",
    "\n",
    "#run transformix on points\n",
    "points_file = point_transformix(pretransform_text_file, transformfile, transformed_dst)\n",
    "#Points_file is a .txt file of transformed points. The unpack_pnts function can be modified to read in this\n",
    "#file into an array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
