{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:35563/v/3b799a776cf4ea2bdeb779114fa4ed5a6b8ae211/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import ast\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neuroglancer\n",
    "from tqdm import tqdm\n",
    "from skimage import io\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), '../'))\n",
    "from utilities.file_location import FileLocationManager\n",
    "from utilities.sqlcontroller import SqlController\n",
    "\n",
    "viewer = neuroglancer.Viewer()\n",
    "print(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal = 'MD589'\n",
    "aligned_shape = np.array((47000, 23300)) // 32\n",
    "num_section = 433\n",
    "# animal = 'MD585'\n",
    "# aligned_shape = np.array((38200, 28000)) // 32\n",
    "# num_section = 446\n",
    "# animal = 'MD589'\n",
    "# aligned_shape = np.array((43700, 32400)) // 32\n",
    "# num_section = 447\n",
    "\n",
    "color_filepath = os.path.join('../', 'neuroglancer/contours/json_cache', 'struct_to_color_2.json')\n",
    "with open(color_filepath, 'r') as json_file:\n",
    "    colors = json.load(json_file)\n",
    "colors = {name.upper(): index for name, index in colors.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the annotation points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [00:06<00:00, 10.22it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_dense_coordinates(coor_list):\n",
    "    dense_coor_list = []\n",
    "    # Shortest distance, x, y\n",
    "\n",
    "    # for x, y in coor_list:\n",
    "    for i in range(len(coor_list) - 1):\n",
    "        x, y = coor_list[i]\n",
    "        x_next, y_next = coor_list[i + 1]\n",
    "\n",
    "        x_mid = (x + x_next) / 2\n",
    "        y_mid = (y + y_next) / 2\n",
    "\n",
    "        dense_coor_list.append([x, y])\n",
    "        dense_coor_list.append([x_mid, y_mid])\n",
    "\n",
    "        if i == len(coor_list) - 2:\n",
    "            dense_coor_list.append([x_next, y_next])\n",
    "            x, y = coor_list[0]\n",
    "            x_mid = (x + x_next) / 2\n",
    "            y_mid = (y + y_next) / 2\n",
    "            dense_coor_list.append([x_mid, y_mid])\n",
    "\n",
    "    return dense_coor_list\n",
    "\n",
    "def get_contours_from_annotations(stack, target_structure, hand_annotations, densify=0):\n",
    "    MD585_ng_section_min = 83\n",
    "    num_annotations = len(hand_annotations)\n",
    "    str_contours_annotation = {}\n",
    "\n",
    "    for i in range(num_annotations):\n",
    "        structure = hand_annotations['name'][i]\n",
    "        side = hand_annotations['side'][i]\n",
    "        section = hand_annotations['section'][i]\n",
    "        first_sec = 0\n",
    "        last_sec = 0\n",
    "\n",
    "        #if side == 'R' or side == 'L':\n",
    "        #    structure = structure + '_' + side\n",
    "\n",
    "        if structure == target_structure:\n",
    "            vertices = hand_annotations['vertices'][i]\n",
    "\n",
    "            for i in range(densify):\n",
    "                vertices = get_dense_coordinates(vertices)\n",
    "\n",
    "            # Skip sections before the 22nd prep2 section for MD585 as there are clear errors\n",
    "            if stack == 'MD585' and section < MD585_ng_section_min + 22:\n",
    "                # vertices = vertices - np.array(MD585_abberation_correction)\n",
    "                continue\n",
    "            str_contours_annotation[section] = {}\n",
    "            str_contours_annotation[section][structure] = {}\n",
    "            str_contours_annotation[section][structure][1] = vertices\n",
    "\n",
    "    try:\n",
    "        first_sec = np.min(list(str_contours_annotation.keys()))\n",
    "        last_sec = np.max(list(str_contours_annotation.keys()))\n",
    "    except:\n",
    "        pass\n",
    "    return str_contours_annotation, first_sec, last_sec\n",
    "\n",
    "CSV_PATH = '/net/birdstore/Active_Atlas_Data/data_root/atlas_data/foundation_brain_annotations'\n",
    "csvfile = os.path.join(CSV_PATH, f'{animal}_annotation.csv')\n",
    "hand_annotations = pd.read_csv(csvfile)\n",
    "hand_annotations['vertices'] = hand_annotations['vertices'] \\\n",
    "    .apply(lambda x: x.replace(' ', ','))\\\n",
    "    .apply(lambda x: x.replace('\\n',','))\\\n",
    "    .apply(lambda x: x.replace(',]',']'))\\\n",
    "    .apply(lambda x: x.replace(',,', ','))\\\n",
    "    .apply(lambda x: x.replace(',,', ','))\\\n",
    "    .apply(lambda x: x.replace(',,', ',')).apply(lambda x: x.replace(',,', ','))\n",
    "hand_annotations['vertices'] = hand_annotations['vertices'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "structures = list(hand_annotations['name'].unique())\n",
    "section_structure_vertices = defaultdict(dict)\n",
    "for structure in tqdm(structures):\n",
    "    contour_annotations, first_sec, last_sec = get_contours_from_annotations(animal, structure, hand_annotations, densify=4)\n",
    "    for section in contour_annotations:\n",
    "        section_structure_vertices[section][structure] = contour_annotations[section][structure][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce create_clean transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 447/447 [00:05<00:00, 88.23it/s] \n"
     ]
    }
   ],
   "source": [
    "PATH = f'/net/birdstore/Active_Atlas_Data/data_root/pipeline_data/{animal}/preps/CH1'\n",
    "thumbnail_dir = os.path.join(PATH, 'thumbnail')\n",
    "\n",
    "section_offset = {}\n",
    "for file_name in tqdm(sorted(os.listdir(thumbnail_dir))):\n",
    "    filepath = os.path.join(thumbnail_dir, file_name)\n",
    "    img = io.imread(filepath)\n",
    "    section = int(file_name.split('.')[0])\n",
    "    section_offset[section] = (aligned_shape - img.shape[:2][::-1]) // 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce create_alignment transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_elastix_parameter_file(filepath, tf_type=None):\n",
    "    \"\"\"\n",
    "    Parse elastix parameter result file.\n",
    "    \"\"\"\n",
    "    def parameter_elastix_parameter_file_to_dict(filename):\n",
    "        d = {}\n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                if line.startswith('('):\n",
    "                    tokens = line[1:-2].split(' ')\n",
    "                    key = tokens[0]\n",
    "                    if len(tokens) > 2:\n",
    "                        value = []\n",
    "                        for v in tokens[1:]:\n",
    "                            try:\n",
    "                                value.append(float(v))\n",
    "                            except ValueError:\n",
    "                                value.append(v)\n",
    "                    else:\n",
    "                        v = tokens[1]\n",
    "                        try:\n",
    "                            value = (float(v))\n",
    "                        except ValueError:\n",
    "                            value = v\n",
    "                    d[key] = value\n",
    "            return d\n",
    "\n",
    "    d = parameter_elastix_parameter_file_to_dict(filepath)\n",
    "\n",
    "    if tf_type is None:\n",
    "        # For alignment composition script\n",
    "        rot_rad, x_mm, y_mm = d['TransformParameters']\n",
    "        center = np.array(d['CenterOfRotationPoint']) / np.array(d['Spacing'])\n",
    "        # center[1] = d['Size'][1] - center[1]\n",
    "\n",
    "        xshift = x_mm / d['Spacing'][0]\n",
    "        yshift = y_mm / d['Spacing'][1]\n",
    "\n",
    "        R = np.array([[np.cos(rot_rad), -np.sin(rot_rad)],\n",
    "                      [np.sin(rot_rad), np.cos(rot_rad)]])\n",
    "        shift = center + (xshift, yshift) - np.dot(R, center)\n",
    "        T = np.vstack([np.column_stack([R, shift]), [0, 0, 1]])\n",
    "        return T\n",
    "\n",
    "    elif tf_type == 'rigid3d':\n",
    "        p = np.array(d['TransformParameters'])\n",
    "        center = np.array(d['CenterOfRotationPoint']) / np.array(d['Spacing'])\n",
    "        shift = p[3:] / np.array(d['Spacing'])\n",
    "\n",
    "        thetax, thetay, thetaz = p[:3]\n",
    "        # Important to use the negative angle.\n",
    "        cx = np.cos(-thetax)\n",
    "        cy = np.cos(-thetay)\n",
    "        cz = np.cos(-thetaz)\n",
    "        sx = np.sin(-thetax)\n",
    "        sy = np.sin(-thetay)\n",
    "        sz = np.sin(-thetaz)\n",
    "        Rx = np.array([[1, 0, 0], [0, cx, sx], [0, -sx, cx]])\n",
    "        Ry = np.array([[cy, 0, sy], [0, 1, 0], [-sy, 0, cy]])\n",
    "        Rz = np.array([[cz, sz, 0], [-sz, cz, 0], [0, 0, 1]])\n",
    "\n",
    "        R = np.dot(np.dot(Rz, Ry), Rx)\n",
    "        # R = np.dot(np.dot(Rx, Ry), Rz)\n",
    "        # The order could be Rx,Ry,Rz - not sure.\n",
    "\n",
    "        return R, shift, center\n",
    "\n",
    "    elif tf_type == 'affine3d':\n",
    "        p = np.array(d['TransformParameters'])\n",
    "        L = p[:9].reshape((3, 3))\n",
    "        shift = p[9:] / np.array(d['Spacing'])\n",
    "        center = np.array(d['CenterOfRotationPoint']) / np.array(d['Spacing'])\n",
    "        # shift = center + shift - np.dot(L, center)\n",
    "        # T = np.column_stack([L, shift])\n",
    "        return L, shift, center\n",
    "\n",
    "    elif tf_type == 'bspline3d':\n",
    "        n_params = d['NumberOfParameters']\n",
    "        p = np.array(d['TransformParameters'])\n",
    "        grid_size = d['GridSize']\n",
    "        grid_spacing = d['GridSpacing']\n",
    "        grid_origin = d['GridOrigin']\n",
    "\n",
    "        return L, shift, center\n",
    "\n",
    "def load_consecutive_section_transform(stack, moving_fn, fixed_fn):\n",
    "    \"\"\"\n",
    "    Load pairwise transform.\n",
    "\n",
    "    Returns:\n",
    "        (3,3)-array.\n",
    "    \"\"\"\n",
    "    assert stack is not None\n",
    "    fileLocationManager = FileLocationManager(stack)\n",
    "    elastix_output_dir = fileLocationManager.elastix_dir\n",
    "    param_fp = os.path.join(elastix_output_dir, moving_fn + '_to_' + fixed_fn, 'TransformParameters.0.txt')\n",
    "    #sys.stderr.write('Load elastix-computed transform: %s\\n' % param_fp)\n",
    "    if not os.path.exists(param_fp):\n",
    "        raise Exception('Transform file does not exist: %s to %s, %s' % (moving_fn, fixed_fn, param_fp))\n",
    "    transformation_to_previous_sec = parse_elastix_parameter_file(param_fp)\n",
    "\n",
    "    return transformation_to_previous_sec\n",
    "\n",
    "def convert_resolution_string_to_um(stack, resolution):\n",
    "    def convert_resolution_string_to_voxel_size(stack, resolution):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            resolution (str):\n",
    "        Returns:\n",
    "            voxel/pixel size in microns.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            sqlController = SqlController(stack)\n",
    "            planar_resolution = sqlController.scan_run.resolution\n",
    "        except:\n",
    "            planar_resolution = 0.46\n",
    "        #planar_resolution =  0.452\n",
    "        assert resolution is not None, 'Resolution argument cannot be None.'\n",
    "\n",
    "        if resolution in ['down32', 'thumbnail']:\n",
    "            assert stack is not None\n",
    "            return planar_resolution * 32.\n",
    "        elif resolution == 'lossless' or resolution == 'down1' or resolution == 'raw' or resolution == 'full':\n",
    "            assert stack is not None\n",
    "            return planar_resolution\n",
    "        elif resolution.startswith('down'):\n",
    "            assert stack is not None\n",
    "            return planar_resolution * int(resolution[4:])\n",
    "        elif resolution == 'um':\n",
    "            return 1.\n",
    "        elif resolution.endswith('um'):\n",
    "            return float(resolution[:-2])\n",
    "        else:\n",
    "            print(resolution)\n",
    "            raise Exception(\"Unknown resolution string %s\" % resolution)\n",
    "            \n",
    "    return convert_resolution_string_to_voxel_size(stack, resolution)\n",
    "\n",
    "def parse_elastix(animal):\n",
    "    \"\"\"\n",
    "    After the elastix job is done, this goes into each subdirectory and parses the Transformation.0.txt file\n",
    "    Args:\n",
    "        animal: the animal\n",
    "    Returns: a dictionary of key=filename, value = coordinates\n",
    "    \"\"\"\n",
    "    fileLocationManager = FileLocationManager(animal)\n",
    "    DIR = fileLocationManager.prep\n",
    "    INPUT = os.path.join(DIR, 'CH1', 'thumbnail_cleaned')\n",
    "\n",
    "    image_name_list = sorted(os.listdir(INPUT))\n",
    "    anchor_idx = len(image_name_list) // 2\n",
    "    # anchor_idx = len(image_name_list) - 1\n",
    "    transformation_to_previous_sec = {}\n",
    "\n",
    "    for i in range(1, len(image_name_list)):\n",
    "        fixed_fn = os.path.splitext(image_name_list[i - 1])[0]\n",
    "        moving_fn = os.path.splitext(image_name_list[i])[0]\n",
    "        transformation_to_previous_sec[i] = load_consecutive_section_transform(animal, moving_fn, fixed_fn)\n",
    "\n",
    "    transformation_to_anchor_sec = {}\n",
    "    # Converts every transformation\n",
    "    for moving_idx in range(len(image_name_list)):\n",
    "        if moving_idx == anchor_idx:\n",
    "            transformation_to_anchor_sec[image_name_list[moving_idx]] = np.eye(3)\n",
    "        elif moving_idx < anchor_idx:\n",
    "            T_composed = np.eye(3)\n",
    "            for i in range(anchor_idx, moving_idx, -1):\n",
    "                T_composed = np.dot(np.linalg.inv(transformation_to_previous_sec[i]), T_composed)\n",
    "            transformation_to_anchor_sec[image_name_list[moving_idx]] = T_composed\n",
    "        else:\n",
    "            T_composed = np.eye(3)\n",
    "            for i in range(anchor_idx + 1, moving_idx + 1):\n",
    "                T_composed = np.dot(transformation_to_previous_sec[i], T_composed)\n",
    "            transformation_to_anchor_sec[image_name_list[moving_idx]] = T_composed\n",
    "\n",
    "\n",
    "    return transformation_to_anchor_sec\n",
    "\n",
    "def create_warp_transforms(animal, transforms, transforms_resol, resolution):\n",
    "    def convert_2d_transform_forms(arr):\n",
    "        return np.vstack([arr, [0,0,1]])\n",
    "    \n",
    "    #transforms_resol = op['resolution']\n",
    "    transforms_scale_factor = convert_resolution_string_to_um(animal, resolution=transforms_resol) / convert_resolution_string_to_um(animal, resolution=resolution)\n",
    "    tf_mat_mult_factor = np.array([[1, 1, transforms_scale_factor], [1, 1, transforms_scale_factor]])\n",
    "    transforms_to_anchor = {\n",
    "        img_name:\n",
    "            convert_2d_transform_forms(np.reshape(tf, (3, 3))[:2] * tf_mat_mult_factor) for\n",
    "        img_name, tf in transforms.items()}\n",
    "\n",
    "    return transforms_to_anchor\n",
    "\n",
    "transforms = parse_elastix(animal)\n",
    "warp_transforms = create_warp_transforms(animal, transforms, 'thumbnail', 'thumbnail')\n",
    "ordered_transforms = sorted(warp_transforms.items())\n",
    "\n",
    "section_transform = {}\n",
    "for section, transform in ordered_transforms:\n",
    "    section_num = int(section.split('.')[0])\n",
    "    transform = np.linalg.inv(transform)\n",
    "    section_transform[section_num] = transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment of annotation coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "367",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e12e699201a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoints\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoints\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msection_offset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msection\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# create_clean offset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_create_alignment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msection_transform\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msection\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# create_alignment transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 367"
     ]
    }
   ],
   "source": [
    "'''\n",
    "(x', y') = (x * sx + y * ry + tx, x * rx + y * sy + ty)\n",
    "'sx': T[0, 0], 'sy': T[1, 1], 'rx': T[1, 0], 'ry': T[0, 1], 'tx': T[0, 2], 'ty': T[1, 2]\n",
    "'''\n",
    "def transform_create_alignment(points, transform):\n",
    "    a = np.hstack((points, np.ones((points.shape[0], 1))))\n",
    "    b = transform.T[:, 0:2]\n",
    "    c = np.matmul(a, b)\n",
    "    return c\n",
    "\n",
    "volume = np.zeros((aligned_shape[1], aligned_shape[0], num_section), dtype=np.uint8)\n",
    "for section in section_structure_vertices:\n",
    "    template = np.zeros((aligned_shape[1], aligned_shape[0]), dtype=np.uint8)\n",
    "    for structure in section_structure_vertices[section]:\n",
    "        points = np.array(section_structure_vertices[section][structure])\n",
    "        points = points // 32\n",
    "        points = points + section_offset[section] # create_clean offset\n",
    "        points = transform_create_alignment(points, section_transform[section]) # create_alignment transform\n",
    "        points = points.astype(np.int32)\n",
    "        \n",
    "        try:\n",
    "            color = colors[structure.upper()]\n",
    "        except:\n",
    "            sided = '{}_R'.format(structure)\n",
    "            try:\n",
    "                color = colors[sided]\n",
    "            except:\n",
    "                color = 255\n",
    "            \n",
    "        cv2.polylines(template, [points], True, color, 2, lineType=cv2.LINE_AA)\n",
    "    volume[:, :, section - 1] = template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = np.swapaxes(volume, 0, 1)\n",
    "all_volume_layer = neuroglancer.SegmentationLayer(\n",
    "    source = neuroglancer.LocalVolume(\n",
    "        data=volume, \n",
    "        dimensions=neuroglancer.CoordinateSpace(names=['x', 'y', 'z'], units='nm', scales=[14464, 14464, 20000]), \n",
    "        voxel_offset=(0, 0, 0)\n",
    "    ),\n",
    ")\n",
    "\n",
    "with viewer.txn() as s:\n",
    "    s.layers.clear()\n",
    "    s.layers['all'] = all_volume_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{animal}_annotations.npy', 'wb') as file:\n",
    "    np.save(file, volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
