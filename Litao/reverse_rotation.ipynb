{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting dklab@192.168.1.12:3306\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import ast\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neuroglancer\n",
    "from tqdm import tqdm\n",
    "from skimage import io\n",
    "import imagesize\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), '../'))\n",
    "from utilities.file_location import FileLocationManager\n",
    "from utilities.sqlcontroller import SqlController\n",
    "from utils import get_structure_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal = 'MD589'\n",
    "downsample_factor = 16\n",
    "all_structures = False\n",
    "\n",
    "# OUTPUT_DIR_PATH = os.path.join(os.path.expanduser('~'))\n",
    "OUTPUT_DIR_PATH = os.path.join('./')\n",
    "CSV_DIR_PATH = '/net/birdstore/Active_Atlas_Data/data_root/atlas_data'\n",
    "IMAGE_DIR_PATH = f'/net/birdstore/Active_Atlas_Data/data_root/pipeline_data/{animal}/preps/CH1/full'\n",
    "    \n",
    "sqlController = SqlController(animal)\n",
    "resolution = sqlController.scan_run.resolution\n",
    "aligned_shape = np.array((sqlController.scan_run.width, sqlController.scan_run.height))\n",
    "num_section = len(os.listdir(IMAGE_DIR_PATH))\n",
    "\n",
    "downsampled_aligned_shape = np.round(aligned_shape / downsample_factor).astype(int)\n",
    "scales = np.array([resolution * downsample_factor, resolution * downsample_factor, 20]) * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the annotation points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = os.path.join(CSV_DIR_PATH, f'{animal}.formatted.structures.csv')\n",
    "df = pd.read_csv(csvfile)\n",
    "#csvoutfile = os.path.join(CSV_DIR_PATH, f'{animal}.formatted.structures.csv')\n",
    "#df.to_csv(csvoutfile, index=False)\n",
    "structures = df['structure'].unique()\n",
    "sections = df['section'].unique()\n",
    "section_structure_vertices = defaultdict(dict)\n",
    "for index, row in df.iterrows():\n",
    "    SN = row['section']\n",
    "    ST = row['structure']\n",
    "    section_structure_vertices[SN][ST] = row['vertices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 094.tif\n",
      "95 095.tif\n",
      "96 096.tif\n",
      "97 097.tif\n",
      "98 098.tif\n",
      "99 099.tif\n",
      "100 100.tif\n",
      "101 101.tif\n",
      "102 102.tif\n",
      "103 103.tif\n",
      "104 104.tif\n",
      "105 105.tif\n",
      "106 106.tif\n",
      "107 107.tif\n",
      "108 108.tif\n",
      "109 109.tif\n",
      "110 110.tif\n",
      "111 111.tif\n",
      "112 112.tif\n",
      "113 113.tif\n",
      "114 114.tif\n",
      "115 115.tif\n",
      "116 116.tif\n",
      "117 117.tif\n",
      "118 118.tif\n",
      "119 119.tif\n",
      "120 120.tif\n",
      "121 121.tif\n",
      "122 122.tif\n",
      "123 123.tif\n",
      "124 124.tif\n",
      "125 125.tif\n",
      "126 126.tif\n",
      "127 127.tif\n",
      "128 128.tif\n",
      "129 129.tif\n",
      "130 130.tif\n",
      "131 131.tif\n",
      "132 132.tif\n",
      "133 133.tif\n",
      "134 134.tif\n",
      "135 135.tif\n",
      "136 136.tif\n",
      "137 137.tif\n",
      "138 138.tif\n",
      "139 139.tif\n",
      "140 140.tif\n",
      "141 141.tif\n",
      "142 142.tif\n",
      "143 143.tif\n",
      "144 144.tif\n",
      "145 145.tif\n",
      "146 146.tif\n",
      "147 147.tif\n",
      "148 148.tif\n",
      "149 149.tif\n"
     ]
    }
   ],
   "source": [
    "c = 94\n",
    "for section in sections:\n",
    "    print(c, str(section).zfill(3) + '.tif')\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce create_clean transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "unpack requires a buffer of 2 bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-2dece30044aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Use imread is too slow for full res images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimagesize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdownsampled_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdownsample_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/pipeline/lib/python3.8/site-packages/imagesize.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<L'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mfhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0mifdsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<H\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mifdsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<HHLL\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: unpack requires a buffer of 2 bytes"
     ]
    }
   ],
   "source": [
    "section_offset = {}\n",
    "for file_name in tqdm(sorted(os.listdir(IMAGE_DIR_PATH))):\n",
    "    filepath = os.path.join(IMAGE_DIR_PATH, file_name)\n",
    "    \n",
    "    # Use imread is too slow for full res images\n",
    "    width, height = imagesize.get(filepath)\n",
    "    downsampled_shape = np.round(np.array((width, height)) / downsample_factor)\n",
    "    \n",
    "    section = int(file_name.split('.')[0])\n",
    "    section_offset[section] = (downsampled_aligned_shape - downsampled_shape) // 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce create_alignment transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_elastix_parameter_file(filepath):\n",
    "    \"\"\"\n",
    "    Parse elastix parameter result file.\n",
    "    \"\"\"\n",
    "    def parameter_elastix_parameter_file_to_dict(filename):\n",
    "        d = {}\n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                if line.startswith('('):\n",
    "                    tokens = line[1:-2].split(' ')\n",
    "                    key = tokens[0]\n",
    "                    if len(tokens) > 2:\n",
    "                        value = []\n",
    "                        for v in tokens[1:]:\n",
    "                            try:\n",
    "                                value.append(float(v))\n",
    "                            except ValueError:\n",
    "                                value.append(v)\n",
    "                    else:\n",
    "                        v = tokens[1]\n",
    "                        try:\n",
    "                            value = (float(v))\n",
    "                        except ValueError:\n",
    "                            value = v\n",
    "                    d[key] = value\n",
    "            return d\n",
    "\n",
    "    d = parameter_elastix_parameter_file_to_dict(filepath)\n",
    "\n",
    "    # For alignment composition script\n",
    "    rot_rad, x_mm, y_mm = d['TransformParameters']\n",
    "    center = np.array(d['CenterOfRotationPoint']) / np.array(d['Spacing'])\n",
    "    # center[1] = d['Size'][1] - center[1]\n",
    "\n",
    "    xshift = x_mm / d['Spacing'][0]\n",
    "    yshift = y_mm / d['Spacing'][1]\n",
    "\n",
    "    R = np.array([[np.cos(rot_rad), -np.sin(rot_rad)],\n",
    "                  [np.sin(rot_rad), np.cos(rot_rad)]])\n",
    "    shift = center + (xshift, yshift) - np.dot(R, center)\n",
    "    T = np.vstack([np.column_stack([R, shift]), [0, 0, 1]])\n",
    "    return T\n",
    "\n",
    "\n",
    "def load_consecutive_section_transform(stack, moving_fn, fixed_fn):\n",
    "    \"\"\"\n",
    "    Load pairwise transform.\n",
    "\n",
    "    Returns:\n",
    "        (3,3)-array.\n",
    "    \"\"\"\n",
    "    assert stack is not None\n",
    "    fileLocationManager = FileLocationManager(stack)\n",
    "    elastix_output_dir = fileLocationManager.elastix_dir\n",
    "    param_fp = os.path.join(elastix_output_dir, moving_fn + '_to_' + fixed_fn, 'TransformParameters.0.txt')\n",
    "    #sys.stderr.write('Load elastix-computed transform: %s\\n' % param_fp)\n",
    "    if not os.path.exists(param_fp):\n",
    "        raise Exception('Transform file does not exist: %s to %s, %s' % (moving_fn, fixed_fn, param_fp))\n",
    "    transformation_to_previous_sec = parse_elastix_parameter_file(param_fp)\n",
    "\n",
    "    return transformation_to_previous_sec\n",
    "\n",
    "def parse_elastix(animal):\n",
    "    \"\"\"\n",
    "    After the elastix job is done, this goes into each subdirectory and parses the Transformation.0.txt file\n",
    "    Args:\n",
    "        animal: the animal\n",
    "    Returns: a dictionary of key=filename, value = coordinates\n",
    "    \"\"\"\n",
    "    fileLocationManager = FileLocationManager(animal)\n",
    "    DIR = fileLocationManager.prep\n",
    "    INPUT = os.path.join(DIR, 'CH1', 'thumbnail_cleaned')\n",
    "\n",
    "    image_name_list = sorted(os.listdir(INPUT))\n",
    "    anchor_idx = len(image_name_list) // 2\n",
    "    # anchor_idx = len(image_name_list) - 1\n",
    "    transformation_to_previous_sec = {}\n",
    "\n",
    "    for i in range(1, len(image_name_list)):\n",
    "        fixed_fn = os.path.splitext(image_name_list[i - 1])[0]\n",
    "        moving_fn = os.path.splitext(image_name_list[i])[0]\n",
    "        transformation_to_previous_sec[i] = load_consecutive_section_transform(animal, moving_fn, fixed_fn)\n",
    "\n",
    "    transformation_to_anchor_sec = {}\n",
    "    # Converts every transformation\n",
    "    for moving_idx in range(len(image_name_list)):\n",
    "        if moving_idx == anchor_idx:\n",
    "            transformation_to_anchor_sec[image_name_list[moving_idx]] = np.eye(3)\n",
    "        elif moving_idx < anchor_idx:\n",
    "            T_composed = np.eye(3)\n",
    "            for i in range(anchor_idx, moving_idx, -1):\n",
    "                T_composed = np.dot(np.linalg.inv(transformation_to_previous_sec[i]), T_composed)\n",
    "            transformation_to_anchor_sec[image_name_list[moving_idx]] = T_composed\n",
    "        else:\n",
    "            T_composed = np.eye(3)\n",
    "            for i in range(anchor_idx + 1, moving_idx + 1):\n",
    "                T_composed = np.dot(transformation_to_previous_sec[i], T_composed)\n",
    "            transformation_to_anchor_sec[image_name_list[moving_idx]] = T_composed\n",
    "\n",
    "    return transformation_to_anchor_sec\n",
    "\n",
    "def create_warp_transforms(transforms, downsample_factor=32):\n",
    "    def convert_2d_transform_forms(arr):\n",
    "        return np.vstack([arr, [0, 0, 1]])\n",
    "    \n",
    "    transforms_scale_factor = 32 / downsample_factor \n",
    "    tf_mat_mult_factor = np.array([[1, 1, transforms_scale_factor], [1, 1, transforms_scale_factor]])\n",
    "    transforms_to_anchor = {}\n",
    "    for img_name, tf in transforms.items():\n",
    "        transforms_to_anchor[img_name] = convert_2d_transform_forms(np.reshape(tf, (3, 3))[:2] * tf_mat_mult_factor) \n",
    "\n",
    "    return transforms_to_anchor\n",
    "\n",
    "transforms = parse_elastix(animal)\n",
    "warp_transforms = create_warp_transforms(transforms, downsample_factor)\n",
    "ordered_transforms = sorted(warp_transforms.items())\n",
    "\n",
    "section_transform = {}\n",
    "for section, transform in ordered_transforms:\n",
    "    section_num = int(section.split('.')[0])\n",
    "    transform = np.linalg.inv(transform)\n",
    "    section_transform[section_num] = transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment of annotation coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(x', y') = (x * sx + y * ry + tx, x * rx + y * sy + ty)\n",
    "'sx': T[0, 0], 'sy': T[1, 1], 'rx': T[1, 0], 'ry': T[0, 1], 'tx': T[0, 2], 'ty': T[1, 2]\n",
    "'''\n",
    "def transform_create_alignment(points, transform):\n",
    "    a = np.hstack((points, np.ones((points.shape[0], 1))))\n",
    "    b = transform.T[:, 0:2]\n",
    "    c = np.matmul(a, b)\n",
    "    return c\n",
    "\n",
    "aligned_section_structure_polygons = defaultdict(dict)\n",
    "for section in section_structure_vertices:\n",
    "    for structure in section_structure_vertices[section]:\n",
    "        points = np.array(section_structure_vertices[section][structure]) // downsample_factor\n",
    "        points = points + section_offset[section] # create_clean offset\n",
    "        points = transform_create_alignment(points, section_transform[section]) # create_alignment transform\n",
    "        aligned_section_structure_polygons[section][structure] = [points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "vertices_path = os.path.join(OUTPUT_DIR_PATH, f'{animal}_aligned_section_structure_polygons_down{downsample_factor}.pickle')\n",
    "with open(vertices_path, 'wb') as file:\n",
    "    pickle.dump(aligned_section_structure_polygons, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To this point, aligned_section_structure_polygons variable contains the aligned polygon vertices for each structure in each section. \n",
    "From now on, we introduce how to draw these points to numpy array or neuroglancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw in a numpy volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_numpy(section_structure_polygons, section_start, section_end):\n",
    "    volume = np.zeros((downsampled_aligned_shape[1], downsampled_aligned_shape[0], section_end - section_start), dtype=np.uint8)\n",
    "    for section in tqdm(range(section_start, section_end)):\n",
    "        if section in section_structure_polygons:\n",
    "            template = np.zeros((downsampled_aligned_shape[1], downsampled_aligned_shape[0]), dtype=np.uint8)\n",
    "            for structure in section_structure_polygons[section]:\n",
    "                polygons = section_structure_polygons[section][structure]\n",
    "                for polygon in polygons:\n",
    "                    color = get_structure_number(structure)\n",
    "#                     cv2.polylines(template, [polygon.astype(np.int32)], True, color, 1)\n",
    "                    for point in polygon:\n",
    "                        cv2.circle(template, tuple(point.astype(np.int32)), 0, color, -1)\n",
    "\n",
    "            volume[:, :, section - section_start - 1] = template\n",
    "        \n",
    "    volume = np.swapaxes(volume, 0, 1)\n",
    "    return volume\n",
    "\n",
    "volume = draw_numpy(aligned_section_structure_polygons, 0, num_section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_path = os.path.join(OUTPUT_DIR_PATH, f'{animal}_annotations_down{downsample_factor}.npy')\n",
    "with open(numpy_path, 'wb') as file:\n",
    "    np.save(file, volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_volume_layer = neuroglancer.SegmentationLayer(\n",
    "    source = neuroglancer.LocalVolume(\n",
    "        data=volume, \n",
    "        dimensions=neuroglancer.CoordinateSpace(names=['x', 'y', 'z'], units='nm', scales=scales), \n",
    "        voxel_offset=[0,0,0]\n",
    "    ),\n",
    ")\n",
    "\n",
    "with viewer.txn() as s:\n",
    "    s.layers['all'] = all_volume_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('MD589_CVAT_down32.pkl', 'rb') as file:\n",
    "    cvat_section_structure_polygons = pickle.load(file)\n",
    "volume = draw_numpy(cvat_section_structure_polygons, 0, num_section)\n",
    "\n",
    "all_volume_layer = neuroglancer.SegmentationLayer(\n",
    "    source = neuroglancer.LocalVolume(\n",
    "        data=volume, \n",
    "        dimensions=neuroglancer.CoordinateSpace(names=['x', 'y', 'z'], units='nm', scales=scales), \n",
    "        voxel_offset=[0,0,0]\n",
    "    ),\n",
    ")\n",
    "\n",
    "with viewer.txn() as s:\n",
    "    s.layers['cvat'] = all_volume_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
