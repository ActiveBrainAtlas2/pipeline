{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 1,
>>>>>>> 8e8580f4a516815e4be478b4690c07c53196355f
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "http://127.0.0.1:44693/v/baa453c140b3f013ecc5821b5b1c9fc1dadbdf1c/\n"
=======
      "http://127.0.0.1:36379/v/e4da2927b3cf642eb532fd934253e311b9b2bfbf/\n"
>>>>>>> 8e8580f4a516815e4be478b4690c07c53196355f
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "import os, sys \n",
=======
    "import os \n",
>>>>>>> 8e8580f4a516815e4be478b4690c07c53196355f
    "import cv2\n",
    "import numpy as np\n",
    "import neuroglancer\n",
    "from skimage import io, measure\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "viewer = neuroglancer.Viewer()\n",
    "print(viewer)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting dklab@192.168.1.12:3306\n"
     ]
    }
   ],
   "source": [
    "HOME = os.path.expanduser(\"~\")\n",
    "PATH = os.path.join(HOME, 'programming/pipeline_utility')\n",
    "sys.path.append(PATH)\n",
    "from utilities.imported_atlas_utilities import volume_to_polydata, save_mesh_stl"
   ]
  },
  {
   "cell_type": "code",
=======
>>>>>>> 8e8580f4a516815e4be478b4690c07c53196355f
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_to_shell(mask):\n",
    "    sub_contours = measure.find_contours(mask, 1)\n",
    "\n",
    "    sub_shells = []\n",
    "    for sub_contour in sub_contours:\n",
    "        sub_contour.T[[0, 1]] = sub_contour.T[[1, 0]]\n",
    "        pts = sub_contour.astype(np.int32).reshape((-1, 1, 2))\n",
    "\n",
    "        sub_shell = np.zeros(mask.shape, dtype='uint8')\n",
    "        sub_shell = cv2.polylines(sub_shell, [pts], True, 1, 5, lineType=cv2.LINE_AA)\n",
    "        sub_shells.append(sub_shell)\n",
    "    shell = np.array(sub_shells).sum(axis=0)\n",
    "    \n",
    "    return shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "VOL_DIR = '/net/birdstore/Active_Atlas_Data/data_root/brains_info/masks/MD594/aligned'\n",
=======
    "VOL_DIR = '/net/birdstore/Active_Atlas_Data/data_root/brains_info/masks/MD589/aligned'\n",
>>>>>>> 8e8580f4a516815e4be478b4690c07c53196355f
    "files = sorted(os.listdir(VOL_DIR))\n",
    "\n",
    "volume = []\n",
    "for file in files:\n",
    "    tif = io.imread(os.path.join(VOL_DIR, file))\n",
    "    tif = mask_to_shell(tif)\n",
    "    volume.append(tif)\n",
    "volume = np.array(volume).astype('uint8')\n",
    "volume = np.swapaxes(volume, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1468, 728, 433)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_shape = [-728/2, -1468/2, -433/2]\n",
    "atlas_resolution = 1.0\n",
    "origin = [o/atlas_resolution for o in origin_shape]\n",
    "volume_origin = (volume, origin)\n",
    "aligned_structure = volume_to_polydata(volume=volume_origin,\n",
    "                           num_simplify_iter=3, smooth=True,\n",
    "                           return_vertex_face_list=False)"
=======
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = neuroglancer.SegmentationLayer(\n",
    "    source = neuroglancer.LocalVolume(\n",
    "        data=volume, \n",
    "        dimensions=neuroglancer.CoordinateSpace(names=['x', 'y', 'z'], units='nm', scales=[14720, 14720, 20000]), \n",
    "        voxel_offset=(0, 0, 0)\n",
    "    ),\n",
    ")\n",
    "\n",
    "with viewer.txn() as s:\n",
    "#     s.layers.clear()\n",
    "    s.layers['layer'] = layer"
>>>>>>> 8e8580f4a516815e4be478b4690c07c53196355f
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(HOME, 'tmp', 'meshes', 'MD94_shell.stl')\n",
    "save_mesh_stl(aligned_structure, filepath)"
=======
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tinybrain\n",
    "from cloudvolume import CloudVolume\n",
    "\n",
    "volume = volume\n",
    "factor = (2, 2, 1)\n",
    "volumes = tinybrain.downsample_segmentation(volume, factor=factor, num_mips=2, sparse=False)\n",
    "volumes.insert(0, volume)"
>>>>>>> 8e8580f4a516815e4be478b4690c07c53196355f
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = neuroglancer.SegmentationLayer(\n",
    "    source = neuroglancer.LocalVolume(\n",
    "        data=volume, \n",
    "        dimensions=neuroglancer.CoordinateSpace(names=['x', 'y', 'z'], units='nm', scales=[460, 460, 20000]), \n",
    "        voxel_offset=(0, 0, 0)\n",
    "    ),\n",
    ")\n",
    "\n",
    "with viewer.txn() as s:\n",
    "#     s.layers.clear()\n",
    "    s.layers['layer'] = layer"
=======
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'file:///home/sherry/Projects/pipeline_utility/Litao/MD589_shell'\n",
    "info = CloudVolume.create_new_info(\n",
    "    num_channels = 1,\n",
    "    layer_type = 'segmentation',\n",
    "    data_type = 'uint8', # Channel images might be 'uint8'\n",
    "    encoding = 'raw', # raw, jpeg, compressed_segmentation, fpzip, kempressed\n",
    "    resolution = [14720, 14720, 20000], # Voxel scaling, units are in nanometers\n",
    "    voxel_offset = [0, 0, 0], # x,y,z offset in voxels from the origin\n",
    "    chunk_size = [512, 512, 16], # units are voxels\n",
    "    volume_size = volume.shape, # e.g. a cubic millimeter dataset\n",
    ")\n",
    "vol = CloudVolume(path, info=info, compress=False, progress=False)\n",
    "\n",
    "for mip, volume in enumerate(volumes):\n",
    "    vol.add_scale(np.array(factor) ** mip)\n",
    "    vol.commit_info()\n",
    "    vol = CloudVolume(path, mip=mip, compress=False, progress=False)\n",
    "    vol[:, :, :] = volume[:, :, :]\n",
    "    \n",
    "vol.commit_info()"
>>>>>>> 8e8580f4a516815e4be478b4690c07c53196355f
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
