{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "Image.MAX_IMAGE_PIXELS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_transform_create_alignment(points, transform):\n",
    "    c = np.hstack((points, np.ones((points.shape[0], 1))))\n",
    "    b = transform.copy()[:, 0:2] # Reverse rotation matrix by doing R^-1 = R^T\n",
    "    b[2:, 0:2] = -transform[0:2, 2] # Reverse translation matrix by doing -T\n",
    "    a = np.matmul(c, b)\n",
    "    return a\n",
    "\n",
    "def parse_elastix_parameter_file(filepath):\n",
    "    \"\"\"\n",
    "    Parse elastix parameter result file.\n",
    "    \"\"\"\n",
    "    def parameter_elastix_parameter_file_to_dict(filename):\n",
    "        d = {}\n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                if line.startswith('('):\n",
    "                    tokens = line[1:-2].split(' ')\n",
    "                    key = tokens[0]\n",
    "                    if len(tokens) > 2:\n",
    "                        value = []\n",
    "                        for v in tokens[1:]:\n",
    "                            try:\n",
    "                                value.append(float(v))\n",
    "                            except ValueError:\n",
    "                                value.append(v)\n",
    "                    else:\n",
    "                        v = tokens[1]\n",
    "                        try:\n",
    "                            value = (float(v))\n",
    "                        except ValueError:\n",
    "                            value = v\n",
    "                    d[key] = value\n",
    "            return d\n",
    "\n",
    "    d = parameter_elastix_parameter_file_to_dict(filepath)\n",
    "\n",
    "    # For alignment composition script\n",
    "    rot_rad, x_mm, y_mm = d['TransformParameters']\n",
    "    center = np.array(d['CenterOfRotationPoint']) / np.array(d['Spacing'])\n",
    "    # center[1] = d['Size'][1] - center[1]\n",
    "\n",
    "    xshift = x_mm / d['Spacing'][0]\n",
    "    yshift = y_mm / d['Spacing'][1]\n",
    "\n",
    "    R = np.array([[np.cos(rot_rad), -np.sin(rot_rad)],\n",
    "                  [np.sin(rot_rad), np.cos(rot_rad)]])\n",
    "    shift = center + (xshift, yshift) - np.dot(R, center)\n",
    "    T = np.vstack([np.column_stack([R, shift]), [0, 0, 1]])\n",
    "    return T\n",
    "\n",
    "\n",
    "def load_consecutive_section_transform(animal, moving_fn, fixed_fn):\n",
    "    \"\"\"\n",
    "    Load pairwise transform.\n",
    "\n",
    "    Returns:\n",
    "        (3,3)-array.\n",
    "    \"\"\"\n",
    "    \n",
    "    elastix_output_dir = f'/net/birdstore/Active_Atlas_Data/data_root/pipeline_data/{animal}/preps/elastix'\n",
    "\n",
    "    param_fp = os.path.join(elastix_output_dir, moving_fn + '_to_' + fixed_fn, 'TransformParameters.0.txt')\n",
    "    #sys.stderr.write('Load elastix-computed transform: %s\\n' % param_fp)\n",
    "    if not os.path.exists(param_fp):\n",
    "        raise Exception('Transform file does not exist: %s to %s, %s' % (moving_fn, fixed_fn, param_fp))\n",
    "    transformation_to_previous_sec = parse_elastix_parameter_file(param_fp)\n",
    "\n",
    "    return transformation_to_previous_sec\n",
    "\n",
    "def parse_elastix(animal):\n",
    "    \"\"\"\n",
    "    After the elastix job is done, this goes into each subdirectory and parses the Transformation.0.txt file\n",
    "    Args:\n",
    "        animal: the animal\n",
    "    Returns: a dictionary of key=filename, value = coordinates\n",
    "    \"\"\"\n",
    "    #fileLocationManager = FileLocationManager(animal)\n",
    "    #DIR = fileLocationManager.prep\n",
    "    DIR = f'/net/birdstore/Active_Atlas_Data/data_root/pipeline_data/{animal}/preps'\n",
    "    INPUT = os.path.join(DIR, 'CH1', 'thumbnail_cleaned')\n",
    "\n",
    "    image_name_list = sorted(os.listdir(INPUT))\n",
    "    anchor_idx = len(image_name_list) // 2\n",
    "    # anchor_idx = len(image_name_list) - 1\n",
    "    transformation_to_previous_sec = {}\n",
    "\n",
    "    for i in range(1, len(image_name_list)):\n",
    "        fixed_fn = os.path.splitext(image_name_list[i - 1])[0]\n",
    "        moving_fn = os.path.splitext(image_name_list[i])[0]\n",
    "        transformation_to_previous_sec[i] = load_consecutive_section_transform(animal, moving_fn, fixed_fn)\n",
    "\n",
    "    transformation_to_anchor_sec = {}\n",
    "    # Converts every transformation\n",
    "    for moving_idx in range(len(image_name_list)):\n",
    "        if moving_idx == anchor_idx:\n",
    "            transformation_to_anchor_sec[image_name_list[moving_idx]] = np.eye(3)\n",
    "        elif moving_idx < anchor_idx:\n",
    "            T_composed = np.eye(3)\n",
    "            for i in range(anchor_idx, moving_idx, -1):\n",
    "                T_composed = np.dot(np.linalg.inv(transformation_to_previous_sec[i]), T_composed)\n",
    "            transformation_to_anchor_sec[image_name_list[moving_idx]] = T_composed\n",
    "        else:\n",
    "            T_composed = np.eye(3)\n",
    "            for i in range(anchor_idx + 1, moving_idx + 1):\n",
    "                T_composed = np.dot(transformation_to_previous_sec[i], T_composed)\n",
    "            transformation_to_anchor_sec[image_name_list[moving_idx]] = T_composed\n",
    "\n",
    "    return transformation_to_anchor_sec\n",
    "\n",
    "def create_warp_transforms(transforms, downsample_factor=32):\n",
    "    def convert_2d_transform_forms(arr):\n",
    "        return np.vstack([arr, [0, 0, 1]])\n",
    "    \n",
    "    transforms_scale_factor = 32 / downsample_factor \n",
    "    tf_mat_mult_factor = np.array([[1, 1, transforms_scale_factor], [1, 1, transforms_scale_factor]])\n",
    "    transforms_to_anchor = {}\n",
    "    for img_name, tf in transforms.items():\n",
    "        transforms_to_anchor[img_name] = convert_2d_transform_forms(np.reshape(tf, (3, 3))[:2] * tf_mat_mult_factor) \n",
    "\n",
    "    return transforms_to_anchor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal = 'DK55'\n",
    "downsample_factor = 32\n",
    "CSV_PATH = f'/net/birdstore/Active_Atlas_Data/data_root/atlas_data/{animal}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH = f'/net/birdstore/Active_Atlas_Data/data_root/pipeline_data/{animal}/preps'\n",
    "cshl_csvfile = 'cshl.premotor.csv'\n",
    "cshl_csvpath = os.path.join(CSV_PATH, cshl_csvfile)\n",
    "cshl_df = pd.read_csv(cshl_csvpath, names=['section','x','y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = cshl_df['section'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_size = {}\n",
    "for section in sections:\n",
    "    filename = str(section).zfill(3) + '.tif'\n",
    "    filepath = os.path.join(IMG_PATH, 'CH3/full', filename)\n",
    "    input_image = Image.open(filepath)\n",
    "    rotated_height = input_image.width\n",
    "    section_size[section] = rotated_height\n",
    "    input_image.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in cshl_df.iterrows():\n",
    "    section = row['section']\n",
    "    rotated_height = section_size[section]\n",
    "    cshl_df.at[index,'xp'] = cshl_df.at[index,'y'] \n",
    "    cshl_df.at[index,'yp'] = rotated_height - cshl_df.at[index,'x'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cshl_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the annotation points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_vertices = defaultdict(list)\n",
    "for index, row in cshl_df.iterrows():\n",
    "    section = row['section']\n",
    "    x = row['xp']\n",
    "    y = row['yp']\n",
    "    section_vertices[section].append([x,y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce create_clean transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the difference between the image stack size which is consistent for all images\n",
    "# and the individual shape of the aligned image: use thumbnail \n",
    "INPUT = f'/net/birdstore/Active_Atlas_Data/data_root/pipeline_data/{animal}/preps/CH3/thumbnail'\n",
    "section_offset = {}\n",
    "\n",
    "# these get switched\n",
    "width = 34000\n",
    "height = 60000\n",
    "downsample_factor = 32\n",
    "aligned_shape = np.array((width, height)) / downsample_factor\n",
    "print(aligned_shape)\n",
    "\n",
    "for file_name in sorted(os.listdir(INPUT)):\n",
    "    filepath = os.path.join(INPUT, file_name)    \n",
    "    input_image = Image.open(filepath)\n",
    "    width = input_image.width\n",
    "    height = input_image.height\n",
    "    downsampled_shape = np.array((width, height))\n",
    "    difference = np.round(aligned_shape - downsampled_shape)\n",
    "    section = int(file_name.split('.')[0])\n",
    "    #print(section, difference, width,height)\n",
    "    section_offset[section] = difference / 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(section, downsample_factor, section_offset[224])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce create_alignment transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = parse_elastix(animal)\n",
    "downsample_factor = 32\n",
    "warp_transforms = create_warp_transforms(transforms, downsample_factor)\n",
    "ordered_transforms = sorted(warp_transforms.items())\n",
    "\n",
    "section_transform = {}\n",
    "for filename, transform in ordered_transforms:\n",
    "    section_num = int(filename.split('.')[0])\n",
    "    #transform = np.linalg.inv(transform)\n",
    "    section_transform[section_num] = transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment of annotation coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(x', y') = (x * sx + y * ry + tx, x * rx + y * sy + ty)\n",
    "'sx': T[0, 0], 'sy': T[1, 1], 'rx': T[1, 0], 'ry': T[0, 1], 'tx': T[0, 2], 'ty': T[1, 2]\n",
    "'''\n",
    "def transform_create_alignment(points, transform):\n",
    "    a = np.hstack((points, np.ones((points.shape[0], 1))))\n",
    "    b = transform.T[:, 0:2]\n",
    "    c = np.matmul(a, b)\n",
    "    return c\n",
    "\n",
    "aligned_section_structure_polygons = defaultdict(list)\n",
    "for section, vertices in section_vertices.items():\n",
    "    #points = np.array(vertices) / downsample_factor\n",
    "    points = np.array(vertices)\n",
    "    points = points + section_offset[section] # create_clean offset\n",
    "    points = transform_create_alignment(points, section_transform[section]) # create_alignment transform\n",
    "    aligned_section_structure_polygons[section] = [points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(aligned_section_structure_polygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for section,v in aligned_section_structure_polygons.items():\n",
    "    for x,y in v[0]:\n",
    "        data.append([x,y,section])    \n",
    "\n",
    "df = pd.DataFrame(data, columns=['x','y','section'])\n",
    "df = df.astype({'section':'int32','x': 'float64', 'y':'float64'})\n",
    "outfile = f'/net/birdstore/Active_Atlas_Data/data_root/atlas_data/DK55/cshl2dk.aligned.csv'\n",
    "df.to_csv(outfile, index=False, header=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To this point, aligned_section_structure_polygons variable contains the aligned polygon vertices for each structure in each section. \n",
    "From now on, we introduce how to draw these points to numpy array or neuroglancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#'VCA', 'VCP', 'DC'\n",
    "unpad = lambda x: x[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "section = 224\n",
    "filename = f'{str(section).zfill(3)}.tif'\n",
    "INPUT = '/net/birdstore/Active_Atlas_Data/data_root/pipeline_data/DK55/preps/CH3'\n",
    "outpath = os.path.join(INPUT, '224.out.tif')\n",
    "filepath = os.path.join(INPUT, 'thumbnail_aligned', filename)\n",
    "#filepath = os.path.join(INPUT, '224.norm.rotated.tif')\n",
    "img = cv2.imread(filepath, -1)\n",
    "img = (img/256).astype(np.uint8)\n",
    "clahe = cv2.createCLAHE(clipLimit=30.0, tileGridSize=(4, 4))\n",
    "img = clahe.apply(img)\n",
    "\n",
    "radius = 5\n",
    "color = 255\n",
    "#df = cshl_df.copy()\n",
    "df = df.loc[df['section'] == section]\n",
    "for index, row in df.iterrows():\n",
    "    x = round(row['x']/32) \n",
    "    y = round(row['y']/32)\n",
    "    #print(x,y)\n",
    "    cv2.circle(img, (int(x), int(y)), radius, color, 2)\n",
    "\n",
    "cv2.imwrite(outpath, img)\n",
    "fig=plt.figure(figsize=(26,18), dpi= 100, facecolor='w', edgecolor='k')\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.title('Aligned section:{}'.format(section), fontsize=30)\n",
    "plt.tick_params(axis='x', labelsize=30)\n",
    "plt.tick_params(axis='y', labelsize=30)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
