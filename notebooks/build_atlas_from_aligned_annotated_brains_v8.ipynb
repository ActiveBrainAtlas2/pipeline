{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os,sys\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "from skimage import io\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage.morphology import distance_transform_edt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/home/eddyod/programming/pipeline_utility/src'\n",
    "\n",
    "sys.path.append(PATH)\n",
    "from lib.file_location import DATA_PATH, ROOT_DIR\n",
    "\n",
    "from lib.sqlcontroller import SqlController\n",
    "from lib.utilities_atlas import load_original_volume_all_known_structures_v3, get_centroid_3d, \\\n",
    "    load_alignment_results_v3, transform_points, average_location, \\\n",
    "    convert_to_original_name, name_unsided_to_color, paired_structures, \\\n",
    "    convert_to_left_name, convert_to_right_name, load_original_volume_v2, save_alignment_results_v3, \\\n",
    "    convert_transform_forms, transform_volume_v4, volume_to_polydata, singular_structures, \\\n",
    "    MESH_DIR, average_shape, convert_to_surround_name, mirror_volume_v2, save_original_volume, \\\n",
    "    save_mesh_stl, get_surround_volume_v2, transform_volume_v4, high_contrast_colors, \\\n",
    "    plot_centroid_means_and_covars_3d, all_known_structures_sided, load_data, \\\n",
    "    get_instance_mesh_filepath, images_to_volume_v2, find_contour_points, load_cropbox_v2, \\\n",
    "    load_mean_shape, \\\n",
    "    display_volume_sections, get_structure_mean_positions_filepath\n",
    "from lib.atlas_aligner import Aligner\n",
    "from lib.utilities_alignment import convert_resolution_string_to_um\n",
    "atlas_name = 'atlasV8'\n",
    "ATLAS_PATH = os.path.join(DATA_PATH, 'atlas_data', atlas_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_brain_name = 'MD589'\n",
    "sqlController = SqlController(fixed_brain_name)\n",
    "structures = sqlController.get_structures_list()\n",
    "structures.remove(\"R\")\n",
    "moving_brain_names = ['MD585', 'MD594']\n",
    "resolution = '10.0um'\n",
    "resolution_um = 10.0\n",
    "structure_centroids_all_brains_um_wrt_fixed = []\n",
    "fixed_brain_spec = {'name': fixed_brain_name, 'vol_type': 'annotationAsScore', 'resolution': resolution}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10N_L /net/birdstore/Active_Atlas_Data/data_root/CSHL_volumes/MD589/10.0um_annotationAsScoreVolume/10N_L.npy\n",
      "10N_L /net/birdstore/Active_Atlas_Data/data_root/CSHL_volumes/MD589/10.0um_annotationAsScoreVolume/10N_L_origin_wrt_wholebrain.txt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_domain_origin() got an unexpected keyword argument 'stack'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ea72ce89b022>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m fixed_brain = load_original_volume_all_known_structures_v3(stack_spec=fixed_brain_spec, structures=structures, \n\u001b[0m\u001b[1;32m      2\u001b[0m                                                            in_bbox_wrt='wholebrain')\n\u001b[1;32m      3\u001b[0m \u001b[0mfixed_brain_structure_centroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_centroid_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_brain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfixed_brain_structure_centroids_um\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mresolution_um\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfixed_brain_structure_centroids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstructure_centroids_all_brains_um_wrt_fixed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_brain_structure_centroids_um\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programming/pipeline_utility/src/lib/utilities_atlas.py\u001b[0m in \u001b[0;36mload_original_volume_all_known_structures_v3\u001b[0;34m(stack_spec, structures, in_bbox_wrt)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Score volume for %s does not exist.\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programming/pipeline_utility/src/lib/utilities_atlas.py\u001b[0m in \u001b[0;36mload_original_volume_all_known_structures_v3\u001b[0;34m(stack_spec, structures, in_bbox_wrt)\u001b[0m\n\u001b[1;32m   1027\u001b[0m                                                        resolution=stack_spec['resolution'])\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             in_bbox_origin_wrt_wholebrain = get_domain_origin(stack=stack_spec['name'],\n\u001b[0m\u001b[1;32m   1030\u001b[0m                                                                           \u001b[0mdomain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_bbox_wrt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m                                                                           \u001b[0mresolution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstack_spec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'resolution'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_domain_origin() got an unexpected keyword argument 'stack'"
     ]
    }
   ],
   "source": [
    "fixed_brain = load_original_volume_all_known_structures_v3(stack_spec=fixed_brain_spec, structures=structures, \n",
    "                                                           in_bbox_wrt='wholebrain')\n",
    "fixed_brain_structure_centroids = get_centroid_3d(fixed_brain)\n",
    "fixed_brain_structure_centroids_um = {s: c * resolution_um for s, c in fixed_brain_structure_centroids.items()}\n",
    "structure_centroids_all_brains_um_wrt_fixed.append(fixed_brain_structure_centroids_um)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute instance centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for brain_m in moving_brain_names:\n",
    "    moving_brain_spec = {'name': brain_m, 'vol_type': 'annotationAsScore', 'resolution': resolution}\n",
    "    print('Brain', moving_brain_spec)\n",
    "    moving_brain = load_original_volume_all_known_structures_v3(stack_spec=moving_brain_spec, \n",
    "                                                                structures=structures, in_bbox_wrt='wholebrain')\n",
    "    alignment_spec = dict(stack_m=moving_brain_spec, stack_f=fixed_brain_spec, warp_setting=109)\n",
    "    moving_brain_structure_centroids_input_resol = get_centroid_3d(moving_brain)\n",
    "    # Load registration.\n",
    "    # Alignment results fp: os.path.join(reg_root_dir, alignment_spec['stack_m']['name'], warp_basename, warp_basename + '_' + what + '.' + ext)\n",
    "    transform_parameters_moving_brain_to_fixed_brain = load_alignment_results_v3(alignment_spec=alignment_spec, what='parameters')\n",
    "    # Transform moving brains into alignment with the fixed brain.\n",
    "    transformed_moving_brain_structure_centroids_input_resol_wrt_fixed = \\\n",
    "    dict(list(zip(list(moving_brain_structure_centroids_input_resol.keys()),\n",
    "                  transform_points(pts=list(moving_brain_structure_centroids_input_resol.values()),\n",
    "                                   transform=transform_parameters_moving_brain_to_fixed_brain))))\n",
    "\n",
    "    transformed_moving_brain_structure_centroids_um_wrt_fixed = \\\n",
    "        {s: c * resolution_um for s, c in\n",
    "        list(transformed_moving_brain_structure_centroids_input_resol_wrt_fixed.items())}\n",
    "\n",
    "    structure_centroids_all_brains_um_wrt_fixed.append(transformed_moving_brain_structure_centroids_um_wrt_fixed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_centroids_all_brains_um_grouped_by_structure_wrt_fixed = defaultdict(list)\n",
    "for sc in structure_centroids_all_brains_um_wrt_fixed:\n",
    "    for k, c in sc.items():\n",
    "        structure_centroids_all_brains_um_grouped_by_structure_wrt_fixed[k].append(c)\n",
    "structure_centroids_all_brains_um_grouped_by_structure_wrt_fixed.default_factory = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_centroids, \\\n",
    "instance_centroids_wrt_canonicalAtlasSpace_um, \\\n",
    "canonical_center_wrt_fixed_um, \\\n",
    "canonical_normal, \\\n",
    "transform_matrix_to_canonicalAtlasSpace_um = \\\n",
    "average_location(structure_centroids_all_brains_um_grouped_by_structure_wrt_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(ATLAS_PATH, '1um_meanPositions.pkl')\n",
    "with open(filepath, 'wb') as f:\n",
    "    pickle.dump(nominal_centroids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that all shapes have voxel resolution matching input resolution (10.0 micron).\n",
    "for structure in tqdm(structures):\n",
    "    # for structure in all_known_structures:\n",
    "    # Load instance volumes.\n",
    "    instance_volumes = []\n",
    "    instance_source = []\n",
    "\n",
    "    for brain_name in [fixed_brain_name] + moving_brain_names:\n",
    "        brain_spec = {'name': brain_name, 'vol_type': 'annotationAsScore', 'resolution': resolution}\n",
    "       \n",
    "        if '_L' in structure:\n",
    "            left_instance_vol, _ = load_original_volume_v2(stack_spec=brain_spec,\n",
    "                                                           structure=structure,\n",
    "                                                           return_origin_instead_of_bbox=True,\n",
    "                                                           crop_to_minimal=True)\n",
    "            instance_volumes.append(left_instance_vol[..., ::-1])  # if left, mirror\n",
    "            instance_source.append((brain_name, 'L'))\n",
    "        \n",
    "        else:\n",
    "            right_instance_vol, _ = load_original_volume_v2(stack_spec=brain_spec,\n",
    "                                                            structure=structure,\n",
    "                                                            return_origin_instead_of_bbox=True,\n",
    "                                                            crop_to_minimal=True)\n",
    "            instance_volumes.append(right_instance_vol)  # if right, do not mirror\n",
    "            instance_source.append((brain_name, 'R'))\n",
    "\n",
    "\n",
    "   # Use the first instance as registration target.\n",
    "    # Register every other instance to the first instance.\n",
    "    template_instance_volume = instance_volumes[0]\n",
    "    template_instance_centroid_wrt_templateOrigin = get_centroid_3d(template_instance_volume).astype(np.int16)\n",
    "    template_instance_wrt_templateCentroid = (template_instance_volume, - template_instance_centroid_wrt_templateOrigin)\n",
    "    aligned_moving_instance_wrt_templateCentroid_all_instances = []\n",
    "\n",
    "    for i in range(1, len(instance_volumes)):\n",
    "        # Compute transform.\n",
    "        moving_instance_volume = instance_volumes[i]\n",
    "        aligner = Aligner({0: template_instance_wrt_templateCentroid},\n",
    "                          {0: (moving_instance_volume, np.array((0,0,0)))},\n",
    "                          labelIndexMap_m2f={0:0},\n",
    "                         verbose=False)\n",
    "        aligner.set_centroid(centroid_m='structure_centroid', centroid_f='structure_centroid')\n",
    "        aligner.compute_gradient(smooth_first=True)\n",
    "        lr = 1.\n",
    "        ### max_iter_num was originally 100 and 1000\n",
    "        _, _ = aligner.optimize(tf_type='rigid',\n",
    "                                history_len=100,\n",
    "                                max_iter_num=2 if structure in ['SC', 'IC'] else 3,\n",
    "                                grad_computation_sample_number=None,\n",
    "                                full_lr=np.array([lr, lr, lr, 0.1, 0.1, 0.1]),\n",
    "                                terminate_thresh_trans=.01)\n",
    "\n",
    "\n",
    "        # Transform instances.\n",
    "        T = convert_transform_forms(aligner=aligner, out_form=(3, 4), select_best='max_value')\n",
    "        aligned_moving_instance_volume, aligned_moving_instance_origin_wrt_templateCentroid = \\\n",
    "            transform_volume_v4(volume=(moving_instance_volume, (0, 0, 0)), transform=T,\n",
    "                                return_origin_instead_of_bbox=True)\n",
    "        aligned_moving_instance_wrt_templateCentroid = (\n",
    "        aligned_moving_instance_volume, aligned_moving_instance_origin_wrt_templateCentroid)\n",
    "        aligned_moving_instance_wrt_templateCentroid_all_instances.append(aligned_moving_instance_wrt_templateCentroid)\n",
    "\n",
    "    # Generate meshes for each instance.\n",
    "    volume_origin_list = [template_instance_wrt_templateCentroid] + aligned_moving_instance_wrt_templateCentroid_all_instances\n",
    "    instance_mesh_wrt_templateCentroid_all_instances = [volume_to_polydata(volume, num_simplify_iter=3, smooth=True)\n",
    "        for volume, o in volume_origin_list]\n",
    "\n",
    "\n",
    "    if structure == 'IC' or structure == 'SC':\n",
    "        # IC and SC boundaries are particularly jagged, so do a larger value smoothing.\n",
    "        sigma = 5.\n",
    "    else:\n",
    "        sigma = 2.\n",
    "\n",
    "\n",
    "    mean_shape_wrt_templateCentroid = \\\n",
    "        average_shape(volume_origin_list=volume_origin_list, force_symmetric=(structure in singular_structures),\n",
    "                      sigma=sigma,\n",
    "                      )\n",
    "\n",
    "\n",
    "    wall_level = .5\n",
    "    surround_distance_um = 200.\n",
    "\n",
    "    # Save mean shape.\n",
    "    filename = f'{structure}.npy'\n",
    "    filepath =  os.path.join(ATLAS_PATH, 'structure', filename)\n",
    "    np.save(filepath, np.ascontiguousarray(mean_shape_wrt_templateCentroid[0]))\n",
    "\n",
    "    filename = f'{structure}.txt'\n",
    "    filepath = os.path.join(ATLAS_PATH, 'origin', filename)\n",
    "    np.savetxt(filepath, mean_shape_wrt_templateCentroid[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine standard shapes with standard centroid locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_resolution = '10.0um'\n",
    "atlas_resolution_um = 10.0\n",
    "filepath = os.path.join(ATLAS_PATH, '1um_meanPositions.pkl')\n",
    "nominal_centroids = pickle.load( open(filepath, \"rb\" ) )\n",
    "nominal_centroids_10um = {s: c / atlas_resolution_um for s, c in nominal_centroids.items()}\n",
    "mean_shapes = {name_u: load_mean_shape(atlas_name=atlas_name, structure=name_u, resolution=atlas_resolution) \n",
    "                    for name_u in structures}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for structure in tqdm(structures):\n",
    "\n",
    "    if '_L' in structure:\n",
    "        mean_shape = mirror_volume_v2(volume=mean_shapes[structure], \n",
    "                                      centroid_wrt_origin=-mean_shapes[structure][1],\n",
    "                                      new_centroid=nominal_centroids_10um[structure])\n",
    "    else:\n",
    "        mean_shape = (mean_shapes[structure][0], \n",
    "                        mean_shapes[structure][1] + nominal_centroids_10um[structure])\n",
    "        \n",
    "    volume = mean_shape[0]\n",
    "    origin = mean_shape[1]\n",
    "    \n",
    "    # save origin, this is also the important one\n",
    "    filename = f'{structure}.txt'\n",
    "    filepath = os.path.join(ATLAS_PATH, 'origin', filename)\n",
    "    np.savetxt(filepath, origin)\n",
    "\n",
    "    # Save volume with stated level. This is the important one\n",
    "    filename = f'{structure}.npy'\n",
    "    filepath = os.path.join(ATLAS_PATH, 'structure', filename)\n",
    "    np.save(filepath, volume)\n",
    "    \n",
    "    # mesh\n",
    "    aligned_volume = (mean_shape[0] >= 0.9, mean_shape[1])\n",
    "    aligned_structure = volume_to_polydata(volume=aligned_volume,\n",
    "                           num_simplify_iter=3, smooth=False,\n",
    "                           return_vertex_face_list=False)\n",
    "    filepath = os.path.join(ATLAS_PATH, 'mesh', f'{structure}.stl')\n",
    "    save_mesh_stl(aligned_structure, filepath)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
