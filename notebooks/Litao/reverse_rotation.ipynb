{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import ast\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neuroglancer\n",
    "from tqdm import tqdm\n",
    "from skimage import io\n",
    "\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "#DIR = os.path.join(HOME, 'programming/pipeline_utility/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_transform_create_alignment(points, transform):\n",
    "    c = np.hstack((points, np.ones((points.shape[0], 1))))\n",
    "    b = transform.copy()[:, 0:2] # Reverse rotation matrix by doing R^-1 = R^T\n",
    "    b[2:, 0:2] = -transform[0:2, 2] # Reverse translation matrix by doing -T\n",
    "    a = np.matmul(c, b)\n",
    "    return a\n",
    "\n",
    "def parse_elastix_parameter_file(filepath):\n",
    "    \"\"\"\n",
    "    Parse elastix parameter result file.\n",
    "    \"\"\"\n",
    "    def parameter_elastix_parameter_file_to_dict(filename):\n",
    "        d = {}\n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                if line.startswith('('):\n",
    "                    tokens = line[1:-2].split(' ')\n",
    "                    key = tokens[0]\n",
    "                    if len(tokens) > 2:\n",
    "                        value = []\n",
    "                        for v in tokens[1:]:\n",
    "                            try:\n",
    "                                value.append(float(v))\n",
    "                            except ValueError:\n",
    "                                value.append(v)\n",
    "                    else:\n",
    "                        v = tokens[1]\n",
    "                        try:\n",
    "                            value = (float(v))\n",
    "                        except ValueError:\n",
    "                            value = v\n",
    "                    d[key] = value\n",
    "            return d\n",
    "\n",
    "    d = parameter_elastix_parameter_file_to_dict(filepath)\n",
    "\n",
    "    # For alignment composition script\n",
    "    rot_rad, x_mm, y_mm = d['TransformParameters']\n",
    "    center = np.array(d['CenterOfRotationPoint']) / np.array(d['Spacing'])\n",
    "    # center[1] = d['Size'][1] - center[1]\n",
    "\n",
    "    xshift = x_mm / d['Spacing'][0]\n",
    "    yshift = y_mm / d['Spacing'][1]\n",
    "\n",
    "    R = np.array([[np.cos(rot_rad), -np.sin(rot_rad)],\n",
    "                  [np.sin(rot_rad), np.cos(rot_rad)]])\n",
    "    shift = center + (xshift, yshift) - np.dot(R, center)\n",
    "    T = np.vstack([np.column_stack([R, shift]), [0, 0, 1]])\n",
    "    return T\n",
    "\n",
    "\n",
    "def load_consecutive_section_transform(animal, moving_fn, fixed_fn):\n",
    "    \"\"\"\n",
    "    Load pairwise transform.\n",
    "\n",
    "    Returns:\n",
    "        (3,3)-array.\n",
    "    \"\"\"\n",
    "    \n",
    "    elastix_output_dir = f'/net/birdstore/Active_Atlas_Data/data_root/pipeline_data/{animal}/preps/elastix'\n",
    "\n",
    "    param_fp = os.path.join(elastix_output_dir, moving_fn + '_to_' + fixed_fn, 'TransformParameters.0.txt')\n",
    "    #sys.stderr.write('Load elastix-computed transform: %s\\n' % param_fp)\n",
    "    if not os.path.exists(param_fp):\n",
    "        raise Exception('Transform file does not exist: %s to %s, %s' % (moving_fn, fixed_fn, param_fp))\n",
    "    transformation_to_previous_sec = parse_elastix_parameter_file(param_fp)\n",
    "\n",
    "    return transformation_to_previous_sec\n",
    "\n",
    "def parse_elastix(animal):\n",
    "    \"\"\"\n",
    "    After the elastix job is done, this goes into each subdirectory and parses the Transformation.0.txt file\n",
    "    Args:\n",
    "        animal: the animal\n",
    "    Returns: a dictionary of key=filename, value = coordinates\n",
    "    \"\"\"\n",
    "    #fileLocationManager = FileLocationManager(animal)\n",
    "    #DIR = fileLocationManager.prep\n",
    "    DIR = f'/net/birdstore/Active_Atlas_Data/data_root/pipeline_data/{animal}/preps'\n",
    "    INPUT = os.path.join(DIR, 'CH1', 'thumbnail_cleaned')\n",
    "\n",
    "    image_name_list = sorted(os.listdir(INPUT))\n",
    "    anchor_idx = len(image_name_list) // 2\n",
    "    # anchor_idx = len(image_name_list) - 1\n",
    "    transformation_to_previous_sec = {}\n",
    "\n",
    "    for i in range(1, len(image_name_list)):\n",
    "        fixed_fn = os.path.splitext(image_name_list[i - 1])[0]\n",
    "        moving_fn = os.path.splitext(image_name_list[i])[0]\n",
    "        transformation_to_previous_sec[i] = load_consecutive_section_transform(animal, moving_fn, fixed_fn)\n",
    "\n",
    "    transformation_to_anchor_sec = {}\n",
    "    # Converts every transformation\n",
    "    for moving_idx in range(len(image_name_list)):\n",
    "        if moving_idx == anchor_idx:\n",
    "            transformation_to_anchor_sec[image_name_list[moving_idx]] = np.eye(3)\n",
    "        elif moving_idx < anchor_idx:\n",
    "            T_composed = np.eye(3)\n",
    "            for i in range(anchor_idx, moving_idx, -1):\n",
    "                T_composed = np.dot(np.linalg.inv(transformation_to_previous_sec[i]), T_composed)\n",
    "            transformation_to_anchor_sec[image_name_list[moving_idx]] = T_composed\n",
    "        else:\n",
    "            T_composed = np.eye(3)\n",
    "            for i in range(anchor_idx + 1, moving_idx + 1):\n",
    "                T_composed = np.dot(transformation_to_previous_sec[i], T_composed)\n",
    "            transformation_to_anchor_sec[image_name_list[moving_idx]] = T_composed\n",
    "\n",
    "    return transformation_to_anchor_sec\n",
    "\n",
    "def create_warp_transforms(transforms, downsample_factor=32):\n",
    "    def convert_2d_transform_forms(arr):\n",
    "        return np.vstack([arr, [0, 0, 1]])\n",
    "    \n",
    "    transforms_scale_factor = 32 / downsample_factor \n",
    "    tf_mat_mult_factor = np.array([[1, 1, transforms_scale_factor], [1, 1, transforms_scale_factor]])\n",
    "    transforms_to_anchor = {}\n",
    "    for img_name, tf in transforms.items():\n",
    "        transforms_to_anchor[img_name] = convert_2d_transform_forms(np.reshape(tf, (3, 3))[:2] * tf_mat_mult_factor) \n",
    "\n",
    "    return transforms_to_anchor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal = 'DK55'\n",
    "downsample_factor = 32\n",
    "section = 224\n",
    "PATH = f'/net/birdstore/Active_Atlas_Data/data_root/pipeline_data/{animal}/preps'\n",
    "filename = str(section).zfill(3) + '.tif'\n",
    "filepath = os.path.join(PATH, 'CH3/full', filename)\n",
    "# Use imread is too slow for full res images\n",
    "img = io.imread(filepath)\n",
    "\n",
    "height, width = img.shape\n",
    "xm = width // 2\n",
    "ym = height // 2\n",
    "# OUTPUT_DIR_PATH = os.path.join(os.path.expanduser('~'))\n",
    "OUTPUT_DIR_PATH = os.path.join('./')\n",
    "CSV_DIR_PATH = f'/net/birdstore/Active_Atlas_Data/data_root/atlas_data/{animal}'\n",
    "resolution = 0.325\n",
    "#width = 34000\n",
    "#height = 60000\n",
    "aligned_shape = np.array((60000, 34000))\n",
    "downsampled_aligned_shape = np.round(aligned_shape / downsample_factor).astype(int)\n",
    "scales = np.array([resolution * downsample_factor, resolution * downsample_factor, 20]) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "a = a * np.pi / 180\n",
    "print(midx,midy, math.cos(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cshl_csvfile = 'cshl.premotor.csv'\n",
    "dk_csvfile = 'dklabs.premotor.csv'\n",
    "cshl_csvpath = os.path.join(CSV_DIR_PATH, cshl_csvfile)\n",
    "cshl_df = pd.read_csv(cshl_csvpath, names=['section','x','y'])\n",
    "cshl_df = cshl_df.loc[(cshl_df['section'] == section)]\n",
    "cshl_copy = cshl_df.copy()\n",
    "#(x1,y1)=(âˆ’y,x)\n",
    "#cshl_df['x'] = cshl_copy['y'] * -1\n",
    "#cshl_df['y'] = cshl_copy['x']\n",
    "a = 270\n",
    "a = a * np.pi / 180\n",
    "# Subtract midpoints, so that midpoint is translated to origin\n",
    "# and add it in the end again\n",
    "cshl_df['x'] = (cshl_df['x'] - xm) * math.cos(a) - (cshl_df['y'] - ym) * math.sin(a)   + xm\n",
    "cshl_df['y'] = (cshl_df['x'] - xm) * math.sin(a) + (cshl_df['y'] - ym) * math.cos(a)   + ym\n",
    "\n",
    "dk_csvpath = os.path.join(CSV_DIR_PATH, dk_csvfile)\n",
    "dk_df = pd.read_csv(dk_csvpath, usecols=['Layer', 'x', 'y', 'section'])\n",
    "dk_df = dk_df.loc[(dk_df['Layer'] == 'Premotor') & (dk_df['section'] == section)]\n",
    "dk_df = dk_df.round(0)\n",
    "dk_df = dk_df.astype({'x': 'int32', 'y':'int32'})\n",
    "dk_df = dk_df.sort_values(by=['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>224</td>\n",
       "      <td>-3032.0</td>\n",
       "      <td>45750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>224</td>\n",
       "      <td>-2360.0</td>\n",
       "      <td>45078.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     section       x        y\n",
       "204      224 -3032.0  45750.0\n",
       "205      224 -2360.0  45078.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cshl_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cshl_copy.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the annotation points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures = ['premotor']\n",
    "section_structure_vertices = defaultdict(dict)\n",
    "vertices = []\n",
    "for index, row in cshl_df.iterrows():\n",
    "    SN = section\n",
    "    ST = 'premotor'\n",
    "    x = row['x']\n",
    "    y = row['y']\n",
    "    vertices.append([x,y])\n",
    "    #section_structure_vertices[SN][ST] = row['vertices']\n",
    "section_structure_vertices[section]['premotor'] = vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#section_structure_vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(section, downsample_factor, downsampled_aligned_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce create_clean transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = f'/net/birdstore/Active_Atlas_Data/data_root/pipeline_data/{animal}/preps/CH3'\n",
    "section_offset = {}\n",
    "filename = str(section).zfill(3) + '.tif'\n",
    "aligned_path = os.path.join(IMAGE_PATH, 'thumbnail_aligned', filename)\n",
    "unaligned_path = os.path.join(IMAGE_PATH, 'thumbnail', filename)\n",
    "aligned = io.imread(aligned_path)\n",
    "unaligned = io.imread(unaligned_path)\n",
    "aligned_shape = np.array(aligned.shape)\n",
    "unaligned_shape = np.array(unaligned.shape)\n",
    "\n",
    "#width, height = img.shape\n",
    "#section_offset[section] = (downsampled_aligned_shape - downsampled_shape) // 2\n",
    "section_offset[section] = (aligned_shape - unaligned_shape) // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(downsampled_aligned_shape)\n",
    "print(section, downsample_factor, section_offset)\n",
    "#section_offset[section] = [472,-339]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce create_alignment transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = parse_elastix(animal)\n",
    "warp_transforms = create_warp_transforms(transforms, downsample_factor)\n",
    "ordered_transforms = sorted(warp_transforms.items())\n",
    "\n",
    "section_transform = {}\n",
    "for filename, transform in ordered_transforms:\n",
    "    section_num = int(filename.split('.')[0])\n",
    "    transform = np.linalg.inv(transform)\n",
    "    section_transform[section_num] = transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment of annotation coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(x', y') = (x * sx + y * ry + tx, x * rx + y * sy + ty)\n",
    "'sx': T[0, 0], 'sy': T[1, 1], 'rx': T[1, 0], 'ry': T[0, 1], 'tx': T[0, 2], 'ty': T[1, 2]\n",
    "'''\n",
    "def transform_create_alignment(points, transform):\n",
    "    a = np.hstack((points, np.ones((points.shape[0], 1))))\n",
    "    b = transform.T[:, 0:2]\n",
    "    c = np.matmul(a, b)\n",
    "    return c\n",
    "\n",
    "aligned_section_structure_polygons = defaultdict(dict)\n",
    "for section in section_structure_vertices:\n",
    "    for structure in section_structure_vertices[section]:\n",
    "        points = np.array(section_structure_vertices[section][structure]) // downsample_factor\n",
    "        points = points + section_offset[section] # create_clean offset\n",
    "        points = transform_create_alignment(points, section_transform[section]) # create_alignment transform\n",
    "        aligned_section_structure_polygons[section][structure] = [points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in aligned_section_structure_polygons.items():\n",
    "    for k1,v1 in v.items():\n",
    "        print(k,k1,len(v1[0]))\n",
    "        points = v1[0]\n",
    "\n",
    "df = pd.DataFrame(points, columns=['x','y'])\n",
    "df = df.round(0)\n",
    "df = df.astype({'x': 'int32', 'y':'int32'})\n",
    "#df = df.sort_values(by=['x', 'y'])\n",
    "df['section'] = section\n",
    "#outfile = f'/net/birdstore/Active_Atlas_Data/data_root/atlas_data/DK55/cshl2dk.{section}.csv'\n",
    "#df.to_csv(outfile, index=False)\n",
    "df[['x','y','section']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To this point, aligned_section_structure_polygons variable contains the aligned polygon vertices for each structure in each section. \n",
    "From now on, we introduce how to draw these points to numpy array or neuroglancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#'VCA', 'VCP', 'DC'\n",
    "unpad = lambda x: x[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_name = f'{str(section).zfill(3)}.tif'\n",
    "PATH = '/net/birdstore/Active_Atlas_Data/data_root/pipeline_data/DK55/preps/CH3'\n",
    "outpath = os.path.join(PATH, '224.aligned.out.tif')\n",
    "filepath = os.path.join(PATH, '224.aligned.tif')\n",
    "img = cv2.imread(filepath)\n",
    "radius = 3\n",
    "color = (0,255,0)\n",
    "for index, row in df.iterrows():\n",
    "    x = row['x'] + xm\n",
    "    y = row['y'] + ym\n",
    "    print(x,y)\n",
    "    if x > 10 and y > 10:\n",
    "        cv2.circle(img, (int(x), int(y)), radius, color, 4)\n",
    "\n",
    "#cv2.imwrite(outpath, img)\n",
    "fig=plt.figure(figsize=(26,18), dpi= 100, facecolor='w', edgecolor='k')\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.title('Pre alignment section:{}'.format(section), fontsize=30)\n",
    "plt.tick_params(axis='x', labelsize=30)\n",
    "plt.tick_params(axis='y', labelsize=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#162, 185, 210\n",
    "file_name = f'{str(section).zfill(3)}.tif'\n",
    "filepath = os.path.join(DOWN32, file_name)\n",
    "img = cv2.imread(filepath)\n",
    "section = int(file_name.split('.')[0])\n",
    "color = (0,255,0)\n",
    "radius = 10\n",
    "for structure in section_structure_vertices[section]:\n",
    "    pts = section_structure_vertices[section][structure]\n",
    "    points = np.array(pts, dtype=np.int32)\n",
    "    offset = section_offset[section]\n",
    "    transform = section_transform[section]\n",
    "    \n",
    "    points = reverse_transform_create_alignment(points, section_transform[section]) # reverse create_alignment transform\n",
    "    points = (points - section_offset[section]).astype(np.int32) # reverse create_clean offset\n",
    "    \n",
    "    \n",
    "    cx, cy = np.mean(points, axis=0)\n",
    "    cx = int(cx // 32)\n",
    "    cy = int(cy // 32)\n",
    "    #print(structure,section,'with centers',cx,cy, 'offset', offset, pts)\n",
    "    #cv2.polylines(img, [points], isClosed=True, color=colors[structure], thickness=2)\n",
    "    cv2.circle(img, (cx,cy), radius, color, thickness)\n",
    "    #cv2.putText(img, structure, (int(cx),int(cy)), font,1, colors[structure], 1, cv2.LINE_AA)\n",
    "\n",
    "fig=plt.figure(figsize=(26,18), dpi= 100, facecolor='w', edgecolor='k')\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.title('Pre alignment section:{}'.format(section), fontsize=30)\n",
    "plt.tick_params(axis='x', labelsize=30)\n",
    "plt.tick_params(axis='y', labelsize=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill up a pandas dataframe with the corrected vertices and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "files = sorted(os.listdir(DOWN32))\n",
    "for file_name in files:\n",
    "    section = int(file_name.split('.')[0])\n",
    "    \n",
    "    if section in section_structure_vertices:\n",
    "        for structure in section_structure_vertices[section]:\n",
    "            pts = section_structure_vertices[section][structure]\n",
    "            points = np.array(pts, dtype=np.int32)\n",
    "            points = reverse_transform_create_alignment(points, section_transform[section]) # reverse create_alignment transform\n",
    "            points = points - section_offset[section] # reverse create_clean offset\n",
    "            data.append([structure, section, points])\n",
    "            \n",
    "df = pd.DataFrame(data=data, columns=['structure', 'section', 'vertices'])\n",
    "outpath = os.path.join(CSV_DIR_PATH, f'{animal}_sections.162.185.210.csv')\n",
    "df.to_csv(outpath, index=False)\n",
    "redone_vertices = defaultdict(dict)\n",
    "for index,row in df.iterrows():\n",
    "    section = row['section']\n",
    "    structure = row['structure']\n",
    "    points = row['vertices']\n",
    "    redone_vertices[section][structure] = points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = [162, 185, 210]\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 1\n",
    "file_name = '210.tif'\n",
    "filepath = os.path.join(DOWN32, file_name)\n",
    "img = cv2.imread(filepath)\n",
    "section = int(file_name.split('.')[0])\n",
    "\n",
    "sl = []\n",
    "for structure in section_structure_vertices[section]:\n",
    "    pts = redone_vertices[section][structure]\n",
    "    points = np.array(pts, dtype=np.int32)\n",
    "    cx, cy = np.mean(points, axis=0)\n",
    "    sl.append(structure)\n",
    "    #print(structure,section,'with centers',cx,cy, 'offset', offset)\n",
    "    cv2.polylines(img, [points], isClosed=True, color=colors[structure], thickness=2)\n",
    "    cv2.putText(img, structure, (int(cx-5),int(cy-5)), font,\n",
    "                1, colors[structure], 1, cv2.LINE_AA)\n",
    "\n",
    "fig=plt.figure(figsize=(26,18), dpi= 100, facecolor='w', edgecolor='k')\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.title('MD589 at 1/32 size section:{}, structures {}'.format(section, sl), fontsize=20)\n",
    "plt.tick_params(axis='x', labelsize=30)\n",
    "plt.tick_params(axis='y', labelsize=30)\n",
    "plt.show()\n",
    "fig.savefig(f'/home/eddyod/Desktop/MD589.section{section}.jpg', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
