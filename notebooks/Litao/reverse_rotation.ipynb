{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import ast\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neuroglancer\n",
    "from tqdm import tqdm\n",
    "from skimage import io\n",
    "\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "DIR = os.path.join(HOME, 'programming/pipeline_utility/src')\n",
    "sys.path.append(DIR)\n",
    "#from utilities.file_location import FileLocationManager\n",
    "#from src.utilities.sqlcontroller import SqlController\n",
    "#from src.utilities.utilities_process import get_image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal = 'DK55'\n",
    "downsample_factor = 1\n",
    "all_structures = False\n",
    "section = 224\n",
    "\n",
    "# OUTPUT_DIR_PATH = os.path.join(os.path.expanduser('~'))\n",
    "OUTPUT_DIR_PATH = os.path.join('./')\n",
    "CSV_DIR_PATH = f'/net/birdstore/Active_Atlas_Data/data_root/atlas_data/{animal}'\n",
    "IMAGE_DIR_PATH = f'/net/birdstore/Active_Atlas_Data/data_root/pipeline_data/{animal}/preps/CH3/full'\n",
    "resolution = 0.325\n",
    "aligned_shape = np.array((64000, 34000))\n",
    "num_section = len(os.listdir(IMAGE_DIR_PATH))\n",
    "\n",
    "downsampled_aligned_shape = np.round(aligned_shape / downsample_factor).astype(int)\n",
    "scales = np.array([resolution * downsample_factor, resolution * downsample_factor, 20]) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cshl_csvfile = 'cshl.premotor.csv'\n",
    "dk_csvfile = 'dklabs.premotor.csv'\n",
    "cshl_csvpath = os.path.join(CSV_DIR_PATH, cshl_csvfile)\n",
    "dk_csvpath = os.path.join(CSV_DIR_PATH, dk_csvfile)\n",
    "cshl_df = pd.read_csv(cshl_csvpath)\n",
    "dk_df = pd.read_csv(dk_csvpath, header=None, names=['section', 'x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>221</th>\n",
       "      <th>22359</th>\n",
       "      <th>21440</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221</td>\n",
       "      <td>22359</td>\n",
       "      <td>21456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221</td>\n",
       "      <td>21751</td>\n",
       "      <td>21184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221</td>\n",
       "      <td>22039</td>\n",
       "      <td>21184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221</td>\n",
       "      <td>21815</td>\n",
       "      <td>21024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221</td>\n",
       "      <td>21815</td>\n",
       "      <td>21056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   221  22359  21440\n",
       "0  221  22359  21456\n",
       "1  221  21751  21184\n",
       "2  221  22039  21184\n",
       "3  221  21815  21024\n",
       "4  221  21815  21056"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cshl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Layer</th>\n",
       "      <th>Description</th>\n",
       "      <td>X</td>\n",
       "      <td>Y</td>\n",
       "      <td>Section</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Premotor</th>\n",
       "      <th>NaN</th>\n",
       "      <td>36385.957031</td>\n",
       "      <td>19514.843750</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>36418.734375</td>\n",
       "      <td>19700.191406</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>41504.574219</td>\n",
       "      <td>14066.053711</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>38170.566406</td>\n",
       "      <td>17708.964844</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           section             x        y\n",
       "Layer    Description             X             Y  Section\n",
       "Premotor NaN          36385.957031  19514.843750      124\n",
       "         NaN          36418.734375  19700.191406      124\n",
       "         NaN          41504.574219  14066.053711      128\n",
       "         NaN          38170.566406  17708.964844      136"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dk_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the annotation points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures = ['premotor']\n",
    "section_structure_vertices = defaultdict(dict)\n",
    "vertices = []\n",
    "for index, row in df.iterrows():\n",
    "    SN = section\n",
    "    #ST = row['structure']\n",
    "    ST = 'premotor'\n",
    "    x = row['x']\n",
    "    y = row['y']\n",
    "    vertices.append([x,y])\n",
    "    #section_structure_vertices[SN][ST] = row['vertices']\n",
    "section_structure_vertices[section]['premotor'] = vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#section_structure_vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(section, downsampled_shape, downsample_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce create_clean transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_offset = {}\n",
    "#for file_name in tqdm(sorted(os.listdir(IMAGE_DIR_PATH))):\n",
    "file_name = str(section).zfill(3) + '.tif'\n",
    "filepath = os.path.join(IMAGE_DIR_PATH, file_name)\n",
    "img = io.imread(filepath)\n",
    "width, height = img.shape\n",
    "downsampled_shape = np.round(np.array((width, height)) / downsample_factor)\n",
    "section_offset[section] = (downsampled_aligned_shape - downsampled_shape) // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(section)\n",
    "section_offset[section]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce create_alignment transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_transform_create_alignment(points, transform):\n",
    "    c = np.hstack((points, np.ones((points.shape[0], 1))))\n",
    "    b = transform.copy()[:, 0:2] # Reverse rotation matrix by doing R^-1 = R^T\n",
    "    b[2:, 0:2] = -transform[0:2, 2] # Reverse translation matrix by doing -T\n",
    "    a = np.matmul(c, b)\n",
    "    return a\n",
    "\n",
    "def parse_elastix_parameter_file(filepath):\n",
    "    \"\"\"\n",
    "    Parse elastix parameter result file.\n",
    "    \"\"\"\n",
    "    def parameter_elastix_parameter_file_to_dict(filename):\n",
    "        d = {}\n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                if line.startswith('('):\n",
    "                    tokens = line[1:-2].split(' ')\n",
    "                    key = tokens[0]\n",
    "                    if len(tokens) > 2:\n",
    "                        value = []\n",
    "                        for v in tokens[1:]:\n",
    "                            try:\n",
    "                                value.append(float(v))\n",
    "                            except ValueError:\n",
    "                                value.append(v)\n",
    "                    else:\n",
    "                        v = tokens[1]\n",
    "                        try:\n",
    "                            value = (float(v))\n",
    "                        except ValueError:\n",
    "                            value = v\n",
    "                    d[key] = value\n",
    "            return d\n",
    "\n",
    "    d = parameter_elastix_parameter_file_to_dict(filepath)\n",
    "\n",
    "    # For alignment composition script\n",
    "    rot_rad, x_mm, y_mm = d['TransformParameters']\n",
    "    center = np.array(d['CenterOfRotationPoint']) / np.array(d['Spacing'])\n",
    "    # center[1] = d['Size'][1] - center[1]\n",
    "\n",
    "    xshift = x_mm / d['Spacing'][0]\n",
    "    yshift = y_mm / d['Spacing'][1]\n",
    "\n",
    "    R = np.array([[np.cos(rot_rad), -np.sin(rot_rad)],\n",
    "                  [np.sin(rot_rad), np.cos(rot_rad)]])\n",
    "    shift = center + (xshift, yshift) - np.dot(R, center)\n",
    "    T = np.vstack([np.column_stack([R, shift]), [0, 0, 1]])\n",
    "    return T\n",
    "\n",
    "\n",
    "def load_consecutive_section_transform(animal, moving_fn, fixed_fn):\n",
    "    \"\"\"\n",
    "    Load pairwise transform.\n",
    "\n",
    "    Returns:\n",
    "        (3,3)-array.\n",
    "    \"\"\"\n",
    "    \n",
    "    elastix_output_dir = f'/net/birdstore/Active_Atlas_Data/data_root/pipeline_data/{animal}/preps/elastix'\n",
    "\n",
    "    param_fp = os.path.join(elastix_output_dir, moving_fn + '_to_' + fixed_fn, 'TransformParameters.0.txt')\n",
    "    #sys.stderr.write('Load elastix-computed transform: %s\\n' % param_fp)\n",
    "    if not os.path.exists(param_fp):\n",
    "        raise Exception('Transform file does not exist: %s to %s, %s' % (moving_fn, fixed_fn, param_fp))\n",
    "    transformation_to_previous_sec = parse_elastix_parameter_file(param_fp)\n",
    "\n",
    "    return transformation_to_previous_sec\n",
    "\n",
    "def parse_elastix(animal):\n",
    "    \"\"\"\n",
    "    After the elastix job is done, this goes into each subdirectory and parses the Transformation.0.txt file\n",
    "    Args:\n",
    "        animal: the animal\n",
    "    Returns: a dictionary of key=filename, value = coordinates\n",
    "    \"\"\"\n",
    "    #fileLocationManager = FileLocationManager(animal)\n",
    "    #DIR = fileLocationManager.prep\n",
    "    DIR = f'/net/birdstore/Active_Atlas_Data/data_root/pipeline_data/{animal}/preps'\n",
    "    INPUT = os.path.join(DIR, 'CH1', 'thumbnail_cleaned')\n",
    "\n",
    "    image_name_list = sorted(os.listdir(INPUT))\n",
    "    anchor_idx = len(image_name_list) // 2\n",
    "    # anchor_idx = len(image_name_list) - 1\n",
    "    transformation_to_previous_sec = {}\n",
    "\n",
    "    for i in range(1, len(image_name_list)):\n",
    "        fixed_fn = os.path.splitext(image_name_list[i - 1])[0]\n",
    "        moving_fn = os.path.splitext(image_name_list[i])[0]\n",
    "        transformation_to_previous_sec[i] = load_consecutive_section_transform(animal, moving_fn, fixed_fn)\n",
    "\n",
    "    transformation_to_anchor_sec = {}\n",
    "    # Converts every transformation\n",
    "    for moving_idx in range(len(image_name_list)):\n",
    "        if moving_idx == anchor_idx:\n",
    "            transformation_to_anchor_sec[image_name_list[moving_idx]] = np.eye(3)\n",
    "        elif moving_idx < anchor_idx:\n",
    "            T_composed = np.eye(3)\n",
    "            for i in range(anchor_idx, moving_idx, -1):\n",
    "                T_composed = np.dot(np.linalg.inv(transformation_to_previous_sec[i]), T_composed)\n",
    "            transformation_to_anchor_sec[image_name_list[moving_idx]] = T_composed\n",
    "        else:\n",
    "            T_composed = np.eye(3)\n",
    "            for i in range(anchor_idx + 1, moving_idx + 1):\n",
    "                T_composed = np.dot(transformation_to_previous_sec[i], T_composed)\n",
    "            transformation_to_anchor_sec[image_name_list[moving_idx]] = T_composed\n",
    "\n",
    "    return transformation_to_anchor_sec\n",
    "\n",
    "def create_warp_transforms(transforms, downsample_factor=32):\n",
    "    def convert_2d_transform_forms(arr):\n",
    "        return np.vstack([arr, [0, 0, 1]])\n",
    "    \n",
    "    transforms_scale_factor = 32 / downsample_factor \n",
    "    tf_mat_mult_factor = np.array([[1, 1, transforms_scale_factor], [1, 1, transforms_scale_factor]])\n",
    "    transforms_to_anchor = {}\n",
    "    for img_name, tf in transforms.items():\n",
    "        transforms_to_anchor[img_name] = convert_2d_transform_forms(np.reshape(tf, (3, 3))[:2] * tf_mat_mult_factor) \n",
    "\n",
    "    return transforms_to_anchor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = parse_elastix(animal)\n",
    "warp_transforms = create_warp_transforms(transforms, downsample_factor)\n",
    "ordered_transforms = sorted(warp_transforms.items())\n",
    "\n",
    "section_transform = {}\n",
    "for filename, transform in ordered_transforms:\n",
    "    section_num = int(filename.split('.')[0])\n",
    "    transform = np.linalg.inv(transform)\n",
    "    section_transform[section_num] = transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment of annotation coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(x', y') = (x * sx + y * ry + tx, x * rx + y * sy + ty)\n",
    "'sx': T[0, 0], 'sy': T[1, 1], 'rx': T[1, 0], 'ry': T[0, 1], 'tx': T[0, 2], 'ty': T[1, 2]\n",
    "'''\n",
    "def transform_create_alignment(points, transform):\n",
    "    a = np.hstack((points, np.ones((points.shape[0], 1))))\n",
    "    b = transform.T[:, 0:2]\n",
    "    c = np.matmul(a, b)\n",
    "    return c\n",
    "\n",
    "aligned_section_structure_polygons = defaultdict(dict)\n",
    "for section in section_structure_vertices:\n",
    "    for structure in section_structure_vertices[section]:\n",
    "        points = np.array(section_structure_vertices[section][structure]) // downsample_factor\n",
    "        points = points + section_offset[section] # create_clean offset\n",
    "        points = transform_create_alignment(points, section_transform[section]) # create_alignment transform\n",
    "        aligned_section_structure_polygons[section][structure] = [points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in aligned_section_structure_polygons.items():\n",
    "    for k1,v1 in v.items():\n",
    "        print(k,k1,len(v1[0]))\n",
    "        points = v1[0]\n",
    "df = pd.DataFrame(points, columns=['x','y'])\n",
    "#df = df.loc[(df['y'] > 19000) & (df['y'] < 20000)]\n",
    "\n",
    "df = df.round(0)\n",
    "df = df.astype({'x': 'int32', 'y':'int32'})\n",
    "df = df.sort_values(by=['x', 'y'])\n",
    "df['section'] = section\n",
    "outfile = f'/net/birdstore/Active_Atlas_Data/data_root/atlas_data/DK55/cshl2dk.{section}.csv'\n",
    "df.to_csv(outfile, index=False)\n",
    "df[['x','y','section']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = '/net/birdstore/Active_Atlas_Data/data_root/atlas_data/DK55/premotor.dklabs.csv'\n",
    "dk224df = pd.read_csv(infile, usecols=['Layer', 'X', 'Y', 'Section'])\n",
    "dk224df = dk224df.loc[(dk224df['Layer'] == 'Premotor') & (dk224df['Section'] == section)]\n",
    "#dk224df = dk224df.loc[(dk224df['Y'] > 19000) & (dk224df['Y'] < 20000)]\n",
    "dk224df = dk224df.round(0)\n",
    "dk224df = dk224df.astype({'X': 'int32', 'Y':'int32'})\n",
    "dk224df = dk224df.sort_values(by=['Y', 'X'])\n",
    "dk224df[['X','Y','Section']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "vertices_path = os.path.join(OUTPUT_DIR_PATH, f'{animal}_aligned_section_structure_polygons_down{downsample_factor}.pickle')\n",
    "with open(vertices_path, 'wb') as file:\n",
    "    pickle.dump(aligned_section_structure_polygons, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To this point, aligned_section_structure_polygons variable contains the aligned polygon vertices for each structure in each section. \n",
    "From now on, we introduce how to draw these points to numpy array or neuroglancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 1\n",
    "thickness = 2\n",
    "colors = {}\n",
    "colors['TR_CER'] = (0,255,0)\n",
    "colors['FR_CER'] = (255,0,0)\n",
    "colors['FL_CER'] = (0,255,0)\n",
    "colors['MI_OVAL'] = (255,0,0)\n",
    "#'VCA', 'VCP', 'DC'\n",
    "unpad = lambda x: x[:, :-1]\n",
    "\n",
    "PATH = f'/net/birdstore/Active_Atlas_Data/data_root/pipeline_data/{animal}/preps/CH1'\n",
    "DOWN16 = os.path.join(PATH, 'downsample_16')\n",
    "ALIGNED = os.path.join(PATH, 'downsample_16_aligned')\n",
    "DOWN32 = os.path.join(PATH, 'normalized')\n",
    "ALIGNED32 = os.path.join(PATH, 'thumbnail_aligned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "section = 221\n",
    "file_name = f'{str(section).zfill(3)}.tif'\n",
    "filepath = os.path.join(DOWN32, file_name)\n",
    "img = cv2.imread(filepath)\n",
    "section = int(file_name.split('.')[0])\n",
    "radius = 2\n",
    "color = (255,0,0)\n",
    "for index, row in df.iterrows():\n",
    "    x = row['x'] // 32\n",
    "    y = row['y'] // 32\n",
    "    print(x,y)\n",
    "    cv2.circle(img, (x,y), radius, color, 2)\n",
    "\n",
    "fig=plt.figure(figsize=(26,18), dpi= 100, facecolor='w', edgecolor='k')\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.title('Pre alignment section:{}'.format(section), fontsize=30)\n",
    "plt.tick_params(axis='x', labelsize=30)\n",
    "plt.tick_params(axis='y', labelsize=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#162, 185, 210\n",
    "file_name = f'{str(section).zfill(3)}.tif'\n",
    "filepath = os.path.join(DOWN32, file_name)\n",
    "img = cv2.imread(filepath)\n",
    "section = int(file_name.split('.')[0])\n",
    "color = (0,255,0)\n",
    "radius = 10\n",
    "for structure in section_structure_vertices[section]:\n",
    "    pts = section_structure_vertices[section][structure]\n",
    "    points = np.array(pts, dtype=np.int32)\n",
    "    offset = section_offset[section]\n",
    "    transform = section_transform[section]\n",
    "    \n",
    "    points = reverse_transform_create_alignment(points, section_transform[section]) # reverse create_alignment transform\n",
    "    points = (points - section_offset[section]).astype(np.int32) # reverse create_clean offset\n",
    "    \n",
    "    \n",
    "    cx, cy = np.mean(points, axis=0)\n",
    "    cx = int(cx // 32)\n",
    "    cy = int(cy // 32)\n",
    "    #print(structure,section,'with centers',cx,cy, 'offset', offset, pts)\n",
    "    #cv2.polylines(img, [points], isClosed=True, color=colors[structure], thickness=2)\n",
    "    cv2.circle(img, (cx,cy), radius, color, thickness)\n",
    "    #cv2.putText(img, structure, (int(cx),int(cy)), font,1, colors[structure], 1, cv2.LINE_AA)\n",
    "\n",
    "fig=plt.figure(figsize=(26,18), dpi= 100, facecolor='w', edgecolor='k')\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.title('Pre alignment section:{}'.format(section), fontsize=30)\n",
    "plt.tick_params(axis='x', labelsize=30)\n",
    "plt.tick_params(axis='y', labelsize=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill up a pandas dataframe with the corrected vertices and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "files = sorted(os.listdir(DOWN32))\n",
    "for file_name in files:\n",
    "    section = int(file_name.split('.')[0])\n",
    "    \n",
    "    if section in section_structure_vertices:\n",
    "        for structure in section_structure_vertices[section]:\n",
    "            pts = section_structure_vertices[section][structure]\n",
    "            points = np.array(pts, dtype=np.int32)\n",
    "            points = reverse_transform_create_alignment(points, section_transform[section]) # reverse create_alignment transform\n",
    "            points = points - section_offset[section] # reverse create_clean offset\n",
    "            data.append([structure, section, points])\n",
    "            \n",
    "df = pd.DataFrame(data=data, columns=['structure', 'section', 'vertices'])\n",
    "outpath = os.path.join(CSV_DIR_PATH, f'{animal}_sections.162.185.210.csv')\n",
    "df.to_csv(outpath, index=False)\n",
    "redone_vertices = defaultdict(dict)\n",
    "for index,row in df.iterrows():\n",
    "    section = row['section']\n",
    "    structure = row['structure']\n",
    "    points = row['vertices']\n",
    "    redone_vertices[section][structure] = points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = [162, 185, 210]\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 1\n",
    "file_name = '210.tif'\n",
    "filepath = os.path.join(DOWN32, file_name)\n",
    "img = cv2.imread(filepath)\n",
    "section = int(file_name.split('.')[0])\n",
    "\n",
    "sl = []\n",
    "for structure in section_structure_vertices[section]:\n",
    "    pts = redone_vertices[section][structure]\n",
    "    points = np.array(pts, dtype=np.int32)\n",
    "    cx, cy = np.mean(points, axis=0)\n",
    "    sl.append(structure)\n",
    "    #print(structure,section,'with centers',cx,cy, 'offset', offset)\n",
    "    cv2.polylines(img, [points], isClosed=True, color=colors[structure], thickness=2)\n",
    "    cv2.putText(img, structure, (int(cx-5),int(cy-5)), font,\n",
    "                1, colors[structure], 1, cv2.LINE_AA)\n",
    "\n",
    "fig=plt.figure(figsize=(26,18), dpi= 100, facecolor='w', edgecolor='k')\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.title('MD589 at 1/32 size section:{}, structures {}'.format(section, sl), fontsize=20)\n",
    "plt.tick_params(axis='x', labelsize=30)\n",
    "plt.tick_params(axis='y', labelsize=30)\n",
    "plt.show()\n",
    "fig.savefig(f'/home/eddyod/Desktop/MD589.section{section}.jpg', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
