{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import ast, os, sys\n",
    "import neuroglancer\n",
    "import matplotlib\n",
    "import cv2\n",
    "from skimage import img_as_ubyte\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/home/eddyod/programming/pipeline_utility'\n",
    "sys.path.append(PATH)\n",
    "from utilities.contour_utilities import get_contours_from_annotations, add_structure_to_neuroglancer\n",
    "neuroglancer.set_server_bind_address(bind_port='33645')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = '/net/birdstore/Active_Atlas_Data/data_root/CSHL_volumes/MD589'\n",
    "ATLASPATH = os.path.join(DIR, 'MD594')\n",
    "contourpath = os.path.join(DIR, 'full_brain_volume_annotated.npy')\n",
    "#contourpath = os.path.join('/home/eddyod/programming/pipeline_utility/neuroglancer', 'aligned_moving_instance.npy')\n",
    "contour = np.load(contourpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour = img_as_ubyte(contour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour.dtype, contour.shape, np.median(contour), np.mean(contour), np.amax(contour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.median(contour)\n",
    "keep_mask = contour==M\n",
    "vm = np.where(contour>M,0,1)\n",
    "vm[keep_mask] = M\n",
    "vm = vm.astype(np.uint8)\n",
    "vm.dtype, vm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ng_structure_volume = structure_volumes[0]\n",
    "vm = np.swapaxes(contour,0,2)\n",
    "#vol_m = np.swapaxes(vm, 0,1)\n",
    "vm.shape, vm.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = vm\n",
    "limit = 120\n",
    "start = (arr.shape[2] // 2) - limit\n",
    "end = start + limit * 2\n",
    "nrows = end - start\n",
    "ncols = 1\n",
    "plt.style.use('classic')\n",
    "for i in range(start, end, 4):\n",
    "    plt.title('Z {}'.format(i))\n",
    "    plt.imshow(arr[:,:,i], cmap=\"cool\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = os.path.join(PATH, 'neuroglancer/contours','MD589_annotation_contours.csv')\n",
    "MD589_annotations = pd.read_csv(csvfile)\n",
    "MD589_annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MD589_annotations.groupby(['creator', 'name']).count()[['edits']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_annotations.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal = 'atlasV7'\n",
    "target_structure = 'Tz'\n",
    "str_contours_annotation, first_sec, last_sec = get_contours_from_annotations(animal, target_structure, hand_annotations, densify=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sec, last_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = neuroglancer.CoordinateSpace(\n",
    "    names=['x', 'y', 'z'],\n",
    "    units='nm',\n",
    "    scales=[10, 10, 10])\n",
    "\n",
    "viewer = neuroglancer.Viewer()\n",
    "with viewer.txn() as s:\n",
    "    s.dimensions = dimensions\n",
    "    s.layers['Altas'] = neuroglancer.ImageLayer(\n",
    "        source=neuroglancer.LocalVolume(\n",
    "            data=contour,\n",
    "            dimensions=neuroglancer.CoordinateSpace(\n",
    "                names=['x', 'y', 'z'],\n",
    "                units=['nm','nm','nm'],\n",
    "                scales=[5, 5, 5]),\n",
    "            voxel_offset=(0, 0, 0),\n",
    "        ),\n",
    "        shader=\"\"\"\n",
    "#uicontrol float min slider(min=0, max=1, default=0)\n",
    "#uicontrol float max slider(min=0, max=1, default=1)\n",
    "#uicontrol float invert slider(min=0, max=1, default=0, step=1)\n",
    "#uicontrol float brightness slider(min=-1, max=1)\n",
    "#uicontrol float contrast slider(min=-3, max=3, step=0.01)\n",
    "void main() {\n",
    "  float pix_val = toNormalized(getDataValue());\n",
    "  if(pix_val < min){\n",
    "  \tpix_val = 0.0;\n",
    "  }\n",
    "  if(pix_val > max){\n",
    "    pix_val = 1.0;\n",
    "  }\n",
    "\n",
    "  if(invert==1.0){\n",
    "  \t  emitGrayscale((1.0 -(pix_val - brightness)) *\n",
    "       exp(contrast));\n",
    "  }\n",
    "  else{\n",
    "    emitGrayscale((pix_val + brightness) *\n",
    "                  exp(contrast));\n",
    "  }\n",
    "\n",
    "}\n",
    "\n",
    "\"\"\")\n",
    "print(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = os.path.join(PATH, 'neuroglancer/contours', 'hand_annotations.csv')\n",
    "hand_annotations = pd.read_csv(csvfile)\n",
    "hand_annotations['vertices'] = hand_annotations['vertices'].apply(lambda x: ast.literal_eval(x))\n",
    "animal = 'MD589'\n",
    "color_codes = {\"3N\": 3, \"4N\": 4, \"5N\": 5, \"6N\": 6, \"Tz\": 24, \"VCA_L\": 25, \"VCA_R\": 25}\n",
    "viewer = neuroglancer.Viewer()\n",
    "# Sets 'Image' layer to be MD585 prep2 images from S3\n",
    "with viewer.txn() as s:\n",
    "    s.layers[animal] = neuroglancer.ImageLayer(source='precomputed://https://mousebrainatlas-datajoint-jp2k.s3.amazonaws.com/precomputed/'+animal+'_fullres')\n",
    "    s.layout = 'xy' # '3d'/'4panel'/'xy'\n",
    "print(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroglancer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "structure_volumes = []\n",
    "offsets = []\n",
    "structures = ['3N', '4N', '5N', '6N', 'Tz']\n",
    "for target_structure in structures:\n",
    "    color = color_codes[target_structure]\n",
    "    str_contours_annotation, first_sec, last_sec = get_contours_from_annotations(animal, target_structure, hand_annotations, densify=0)\n",
    "    ng_structure_volume, xyz_offsets = add_structure_to_neuroglancer(viewer, str_contours_annotation, target_structure, animal, first_sec, last_sec, \\\n",
    "                                                        color_radius=2, xy_ng_resolution_um=5, threshold=1, color=color, \\\n",
    "                                                        solid_volume=False, no_offset_big_volume=True, save_results=False, \\\n",
    "                                                        return_with_offsets=True, add_to_ng=True, human_annotation=True )\n",
    "    structure_volumes.append(ng_structure_volume)\n",
    "    offsets.append(xyz_offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures = ['3N', '4N', '5N', '6N', 'Tz']\n",
    "for structure, volume, offset in zip(structures, structure_volumes,offsets):\n",
    "    vm = np.swapaxes(volume,0,2)\n",
    "    print(structure, vm.shape, offset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
