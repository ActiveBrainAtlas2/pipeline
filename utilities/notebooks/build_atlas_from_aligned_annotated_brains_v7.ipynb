{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os,sys\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting dklab@192.168.1.12:3306\n"
     ]
    }
   ],
   "source": [
    "PATH = '/home/eddyod/programming/pipeline_utility'\n",
    "MESH_DIR = '/net/birdstore/Active_Atlas_Data/data_root/CSHL_meshes'\n",
    "sys.path.append(PATH)\n",
    "from utilities.imported_atlas_utilities import load_original_volume_all_known_structures_v3, get_centroid_3d, \\\n",
    "    load_alignment_results_v3, transform_points, average_location, \\\n",
    "    convert_to_original_name, name_unsided_to_color, paired_structures, \\\n",
    "    convert_to_left_name, convert_to_right_name, load_original_volume_v2, save_alignment_results_v3, \\\n",
    "    convert_transform_forms, transform_volume_v4, volume_to_polydata, singular_structures, \\\n",
    "    MESH_DIR, average_shape, convert_to_surround_name, \\\n",
    "    save_mesh_stl, get_surround_volume_v2, transform_volume_v4, launch_vtk, actor_mesh, high_contrast_colors, \\\n",
    "    add_axes, plot_centroid_means_and_covars_3d, all_known_structures_sided\n",
    "from utilities.aligner_v3 import Aligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_KEY_LOC = os.path.join(PATH, 'neuroglancer', 'structure_key_minimal.json')\n",
    "NUM_STRUCTS = 49\n",
    "with open(INPUT_KEY_LOC, 'r') as f:\n",
    "    structures = json.load(f)\n",
    "structures = list(structures.values())\n",
    "structures = structures[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures = ['IC', 'SC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_name = 'atlasV7'\n",
    "fixed_brain_name = 'MD589'\n",
    "moving_brain_names = ['MD585', 'MD594']\n",
    "resolution = '10.0um'\n",
    "resolution_um = 10.0\n",
    "structure_centroids_all_brains_um_wrt_fixed = []\n",
    "fixed_brain_spec = {'name': fixed_brain_name, 'vol_type': 'annotationAsScore', 'resolution': resolution}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prior structure/index map not found. Generating a new one.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "/net/birdstore/Active_Atlas_Data/data_root/CSHL_volumes/MD589/10.0um_annotationAsScoreVolume/IC_origin_wrt_canonicalAtlasSpace.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-01b63d15bfb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfixed_brain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_original_volume_all_known_structures_v3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfixed_brain_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstructures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstructures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfixed_brain_structure_centroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_centroid_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_brain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fixed_brain_structure_centroids'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_brain_structure_centroids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfixed_brain_structure_centroids_um\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mresolution_um\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfixed_brain_structure_centroids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fixed_brain_structure_centroids_um'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_brain_structure_centroids_um\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programming/pipeline_utility/utilities/imported_atlas_utilities.py\u001b[0m in \u001b[0;36mload_original_volume_all_known_structures_v3\u001b[0;34m(stack_spec, structures, in_bbox_wrt)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Score volume for %s does not exist.\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programming/pipeline_utility/utilities/imported_atlas_utilities.py\u001b[0m in \u001b[0;36mload_original_volume_all_known_structures_v3\u001b[0;34m(stack_spec, structures, in_bbox_wrt)\u001b[0m\n\u001b[1;32m    994\u001b[0m                 \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure_to_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m             v, o = load_original_volume_v2(stack_spec, structure=structure,\n\u001b[0m\u001b[1;32m    997\u001b[0m                                                        \u001b[0mbbox_wrt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_bbox_wrt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m                                                        resolution=stack_spec['resolution'])\n",
      "\u001b[0;32m~/programming/pipeline_utility/utilities/imported_atlas_utilities.py\u001b[0m in \u001b[0;36mload_original_volume_v2\u001b[0;34m(stack_spec, structure, resolution, bbox_wrt, return_origin_instead_of_bbox, crop_to_minimal)\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVOL_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{}_annotationAsScoreVolume'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0;31m#origin_filename = get_original_volume_origin_filepath_v3(stack_spec=stack_spec, structure=structure, wrt=bbox_wrt, resolution=resolution)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m     \u001b[0morigin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcrop_to_minimal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/pipeline/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m    979\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/pipeline/lib/python3.8/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/pipeline/lib/python3.8/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    621\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    622\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: /net/birdstore/Active_Atlas_Data/data_root/CSHL_volumes/MD589/10.0um_annotationAsScoreVolume/IC_origin_wrt_canonicalAtlasSpace.txt not found."
     ]
    }
   ],
   "source": [
    "fixed_brain = load_original_volume_all_known_structures_v3(stack_spec=fixed_brain_spec, structures=structures)\n",
    "fixed_brain_structure_centroids = get_centroid_3d(fixed_brain)\n",
    "print('fixed_brain_structure_centroids', fixed_brain_structure_centroids)\n",
    "fixed_brain_structure_centroids_um = {s: c * resolution_um for s, c in fixed_brain_structure_centroids.items()}\n",
    "print('fixed_brain_structure_centroids_um', fixed_brain_structure_centroids_um)\n",
    "structure_centroids_all_brains_um_wrt_fixed.append(fixed_brain_structure_centroids_um)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute instance centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for brain_m in moving_brain_names:\n",
    "    moving_brain_spec = {'name': brain_m, 'vol_type': 'annotationAsScore', 'resolution': resolution}\n",
    "    print('Brain', moving_brain_spec)\n",
    "    moving_brain = load_original_volume_all_known_structures_v3(stack_spec=moving_brain_spec, structures=structures)\n",
    "    alignment_spec = dict(stack_m=moving_brain_spec, stack_f=fixed_brain_spec, warp_setting=109)\n",
    "    moving_brain_structure_centroids_input_resol = get_centroid_3d(moving_brain)\n",
    "    # Load registration.\n",
    "    # Alignment results fp: os.path.join(reg_root_dir, alignment_spec['stack_m']['name'], warp_basename, warp_basename + '_' + what + '.' + ext)\n",
    "    transform_parameters_moving_brain_to_fixed_brain = load_alignment_results_v3(alignment_spec=alignment_spec, what='parameters')\n",
    "    # Transform moving brains into alignment with the fixed brain.\n",
    "    transformed_moving_brain_structure_centroids_input_resol_wrt_fixed = \\\n",
    "    dict(list(zip(list(moving_brain_structure_centroids_input_resol.keys()),\n",
    "                  transform_points(pts=list(moving_brain_structure_centroids_input_resol.values()),\n",
    "                                   transform=transform_parameters_moving_brain_to_fixed_brain))))\n",
    "\n",
    "    transformed_moving_brain_structure_centroids_um_wrt_fixed = \\\n",
    "        {s: c * resolution_um for s, c in\n",
    "        list(transformed_moving_brain_structure_centroids_input_resol_wrt_fixed.items())}\n",
    "\n",
    "    structure_centroids_all_brains_um_wrt_fixed.append(transformed_moving_brain_structure_centroids_um_wrt_fixed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_centroids_all_brains_um_grouped_by_structure_wrt_fixed = defaultdict(list)\n",
    "for sc in structure_centroids_all_brains_um_wrt_fixed:\n",
    "    for k, c in sc.items():\n",
    "        structure_centroids_all_brains_um_grouped_by_structure_wrt_fixed[k].append(c)\n",
    "structure_centroids_all_brains_um_grouped_by_structure_wrt_fixed.default_factory = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute standard centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_centroids_wrt_canonicalAtlasSpace_um, \\\n",
    "instance_centroids_wrt_canonicalAtlasSpace_um, \\\n",
    "canonical_center_wrt_fixed_um, \\\n",
    "canonical_normal, \\\n",
    "transform_matrix_to_canonicalAtlasSpace_um = \\\n",
    "average_location(structure_centroids_all_brains_um_grouped_by_structure_wrt_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {name_s: np.array(name_unsided_to_color[convert_to_original_name(name_s)])/255.\n",
    "                                        for name_s in instance_centroids_wrt_canonicalAtlasSpace_um.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_centroid_means_and_covars_3d(instance_centroids=instance_centroids_wrt_canonicalAtlasSpace_um,\n",
    "                                 nominal_locations=nominal_centroids_wrt_canonicalAtlasSpace_um,\n",
    "                                 canonical_centroid=(0,0,0),\n",
    "                                  show_canonical_centroid=False,\n",
    "                                  canonical_normal=[0,0,1],\n",
    "                                 colors=colors,\n",
    "                                 xlim=[-3000, 3000],\n",
    "                                 ylim=[-3000, 3000],\n",
    "                                 zlim=[-3000, 3000],\n",
    "                                 xlabel='Rostral-caudal ($\\mu$m)',\n",
    "                                 ylabel='',\n",
    "                                 zlabel='Medial-lateral ($\\mu$m)',\n",
    "                                 title='Centroid means and covariances (3 brains)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(MESH_DIR, 'atlasV7', '1um_meanPositions.pkl')\n",
    "with open(filepath, 'wb') as f:\n",
    "    pickle.dump(nominal_centroids_wrt_canonicalAtlasSpace_um, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(MESH_DIR, 'atlasV7', 'canonicalCentroid_wrt_fixedWholebrain.txt')\n",
    "np.savetxt(filepath, canonical_center_wrt_fixed_um)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_root_dir=os.path.join(MESH_DIR, atlas_name, 'mean_shapes', 'instance_registration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that all shapes have voxel resolution matching input resolution (10.0 micron).\n",
    "for structure in ['12N']:\n",
    "    # for structure in all_known_structures:\n",
    "    # Load instance volumes.\n",
    "    instance_volumes = []\n",
    "    instance_source = []\n",
    "\n",
    "    if structure in paired_structures:\n",
    "        left_name = convert_to_left_name(structure)\n",
    "        right_name = convert_to_right_name(structure)\n",
    "    else:\n",
    "        left_name = structure\n",
    "        right_name = structure\n",
    "\n",
    "    for brain_name in [fixed_brain_name] + moving_brain_names:\n",
    "        brain_spec = {'name': brain_name, 'vol_type': 'annotationAsScore', 'resolution': resolution}\n",
    "        right_instance_vol, _ = load_original_volume_v2(stack_spec=brain_spec,\n",
    "                                                        structure=right_name,\n",
    "                                                        return_origin_instead_of_bbox=True,\n",
    "                                                        crop_to_minimal=True)\n",
    "        instance_volumes.append(right_instance_vol)  # if right, do not mirror\n",
    "        instance_source.append((brain_name, 'R'))\n",
    "\n",
    "        left_instance_vol, _ = load_original_volume_v2(stack_spec=brain_spec,\n",
    "                                                       structure=left_name,\n",
    "                                                       return_origin_instead_of_bbox=True,\n",
    "                                                       crop_to_minimal=True)\n",
    "        instance_volumes.append(left_instance_vol[..., ::-1])  # if left, mirror\n",
    "        instance_source.append((brain_name, 'L'))\n",
    "\n",
    "   # Use the first instance as registration target.\n",
    "    # Register every other instance to the first instance.\n",
    "    template_instance_volume = instance_volumes[0]\n",
    "    template_instance_centroid_wrt_templateOrigin = get_centroid_3d(template_instance_volume).astype(np.int16)\n",
    "    template_instance_wrt_templateCentroid = (template_instance_volume, - template_instance_centroid_wrt_templateOrigin)\n",
    "    aligned_moving_instance_wrt_templateCentroid_all_instances = []\n",
    "\n",
    "    for i in range(1, len(instance_volumes)):\n",
    "        print('Registering {} instance {} to instance 0'.format(structure, i))\n",
    "        # Compute transform.\n",
    "        moving_instance_volume = instance_volumes[i]\n",
    "        aligner = Aligner({0: template_instance_wrt_templateCentroid},\n",
    "                          {0: (moving_instance_volume, np.array((0,0,0)))},\n",
    "                          labelIndexMap_m2f={0:0},\n",
    "                         verbose=False)\n",
    "        aligner.set_centroid(centroid_m='structure_centroid', centroid_f='structure_centroid')\n",
    "        aligner.compute_gradient(smooth_first=True)\n",
    "        lr = 1.\n",
    "        ### max_iter_num was originally 100 and 1000\n",
    "        print('Entering aligner optimzer')\n",
    "        _, _ = aligner.optimize(tf_type='rigid',\n",
    "                                history_len=100,\n",
    "                                max_iter_num=2 if structure in ['SC', 'IC'] else 3,\n",
    "                                grad_computation_sample_number=None,\n",
    "                                full_lr=np.array([lr, lr, lr, 0.1, 0.1, 0.1]),\n",
    "                                terminate_thresh_trans=.01)\n",
    "\n",
    "\n",
    "\n",
    "        reg_root_dir=os.path.join(MESH_DIR, atlas_name, 'mean_shapes', 'instance_registration')\n",
    "        save_alignment_results_v3(aligner=aligner,\n",
    "                              select_best='max_value',\n",
    "                              alignment_spec=dict(warp_setting=108,\n",
    "                                                  stack_f=dict(name='%s_instance0' % structure, vol_type='annotationAsScore'),\n",
    "                                                  stack_m=dict(name='%s_instance%d' % (structure, i),\n",
    "                                                               vol_type='annotationAsScore')),\n",
    "                              reg_root_dir=reg_root_dir)\n",
    "\n",
    "        # Transform instances.\n",
    "        T = convert_transform_forms(aligner=aligner, out_form=(3, 4), select_best='max_value')\n",
    "        aligned_moving_instance_volume, aligned_moving_instance_origin_wrt_templateCentroid = \\\n",
    "            transform_volume_v4(volume=(moving_instance_volume, (0, 0, 0)), transform=T,\n",
    "                                return_origin_instead_of_bbox=True)\n",
    "        aligned_moving_instance_wrt_templateCentroid = (\n",
    "        aligned_moving_instance_volume, aligned_moving_instance_origin_wrt_templateCentroid)\n",
    "        aligned_moving_instance_wrt_templateCentroid_all_instances.append(aligned_moving_instance_wrt_templateCentroid)\n",
    "\n",
    "    # Generate meshes for each instance.\n",
    "    volume_origin_list = [template_instance_wrt_templateCentroid] + aligned_moving_instance_wrt_templateCentroid_all_instances\n",
    "    instance_mesh_wrt_templateCentroid_all_instances = [volume_to_polydata(volume, num_simplify_iter=3, smooth=True)\n",
    "        for volume, o in volume_origin_list]\n",
    "\n",
    "    # Save meshes.\n",
    "    for i, mesh_data in enumerate(instance_mesh_wrt_templateCentroid_all_instances):\n",
    "        meshfile = '{}_{}_{}.stl'.format(resolution, structure, str(i))\n",
    "        meshpath = os.path.join(MESH_DIR, atlas_name, 'aligned_instance_meshes', meshfile)\n",
    "        #print('Save stl at {}'.format( meshpath))\n",
    "        save_mesh_stl(mesh_data, meshpath)\n",
    "\n",
    "    filename = '{}_sources.pkl'.format(structure)\n",
    "    filepath = os.path.join(MESH_DIR, atlas_name, 'instance_sources', filename)\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(instance_source, f)\n",
    "\n",
    "    # Compute average shape.\n",
    "\n",
    "    if structure == 'IC' or structure == 'SC':\n",
    "        # IC and SC boundaries are particularly jagged, so do a larger value smoothing.\n",
    "        sigma = 5.\n",
    "    else:\n",
    "        sigma = 2.\n",
    "\n",
    "\n",
    "    mean_shape_wrt_templateCentroid = \\\n",
    "        average_shape(volume_origin_list=volume_origin_list, force_symmetric=(structure in singular_structures),\n",
    "                      sigma=sigma,\n",
    "                      )\n",
    "\n",
    "    for surface_level in np.arange(0.1, 1.1, .1):\n",
    "        print(\"level =\", surface_level, ', volume =',\n",
    "              np.count_nonzero(mean_shape_wrt_templateCentroid[0] > surface_level) * resolution_um ** 3 / 1e9, \"mm^3\")\n",
    "\n",
    "    # Generate meshes for mean shape.\n",
    "    mean_shape_isosurface_polydata_all_levels = {surface_level:\n",
    "                                                     volume_to_polydata(\n",
    "                                                         (mean_shape_wrt_templateCentroid[0] >= surface_level,\n",
    "                                                         mean_shape_wrt_templateCentroid[1]),\n",
    "                                                         num_simplify_iter=3, smooth=True)\n",
    "        for surface_level in np.arange(0.1, 1.1, .1)}\n",
    "\n",
    "    # Identify the surrouding area as additional structure.\n",
    "\n",
    "    wall_level = .5\n",
    "    surround_distance_um = 200.\n",
    "\n",
    "    # changed to v2 to v3 Jul/27/2020 renamed without the _vX\n",
    "    # volume, distance=5, wall_level=0, prob=False, return_origin_instead_of_bbox=True, padding=5\n",
    "    # def get_surround_volume(volume, origin, distance=5, wall_level=0, prob=False, return_origin_instead_of_bbox=True,\n",
    "    #                        padding=5):\n",
    "    surround_wrt_stdShapeCentroid = \\\n",
    "        get_surround_volume_v2(vol=mean_shape_wrt_templateCentroid[0],\n",
    "                               origin=mean_shape_wrt_templateCentroid[1],\n",
    "                               distance=surround_distance_um / resolution_um,\n",
    "                               wall_level=wall_level,\n",
    "                               prob=True,\n",
    "                               return_origin_instead_of_bbox=True,\n",
    "                               padding=5)\n",
    "\n",
    "    # Generate meshes for surrouding area.\n",
    "    surround_isosurface_polydata_all_levels = {surface_level:\n",
    "             volume_to_polydata((surround_wrt_stdShapeCentroid[0] >= surface_level,\n",
    "                                surround_wrt_stdShapeCentroid[1]),\n",
    "                                num_simplify_iter=3, smooth=True)\n",
    "         for surface_level in np.arange(0.1, 1.1, .1)}\n",
    "\n",
    "    # Save mean shape.\n",
    "    filename = '{}_{}_volume.npy'.format(resolution, structure)\n",
    "    filepath =  os.path.join(MESH_DIR, atlas_name, 'mean_shapes', filename)\n",
    "    print('Saving numpy array at', filepath)\n",
    "    np.save(filepath, np.ascontiguousarray(mean_shape_wrt_templateCentroid[0]))\n",
    "\n",
    "    filename = '{}_{}_origin_wrt_meanShapeCentroid.txt'.format(resolution, structure)\n",
    "    filepath = os.path.join(MESH_DIR, atlas_name, 'mean_shapes', filename)\n",
    "    print('Saving numpy text at', filepath)\n",
    "    np.savetxt(filepath, mean_shape_wrt_templateCentroid[1])\n",
    "\n",
    "\n",
    "    for level in np.arange(0.1, 1.1, .1):\n",
    "        filename = '{}_{}_mesh_level_{}.stl'.format(resolution, structure, str(level))\n",
    "        filepath = os.path.join(MESH_DIR, atlas_name, 'mean_shapes', filename)\n",
    "        print('Saving mesh at', filepath)\n",
    "        save_mesh_stl(mean_shape_isosurface_polydata_all_levels[level], filepath)\n",
    "\n",
    "    surround_name = convert_to_surround_name(structure, margin=str(int(surround_distance_um)) + 'um')\n",
    "    filename = '{}_{}_volume.npy'.format(resolution, surround_name)\n",
    "    filepath = os.path.join(MESH_DIR, atlas_name, 'mean_shapes', filename)\n",
    "    print('Saving numpy array at', filepath)\n",
    "    np.save(filepath, np.ascontiguousarray(surround_wrt_stdShapeCentroid[0]))\n",
    "\n",
    "\n",
    "    filename = '{}_{}_origin_wrt_meanShapeCentroid.txt'.format(resolution, surround_name)\n",
    "    filepath = os.path.join(MESH_DIR, atlas_name, 'mean_shapes', filename)\n",
    "    print('Saving numpy text at', filepath)\n",
    "    np.savetxt(filepath, surround_wrt_stdShapeCentroid[1])\n",
    "\n",
    "    for level in np.arange(0.1, 1.1, .1):\n",
    "        filename = '{}_{}_{}.stl'.format(resolution, surround_name, str(level))\n",
    "        filepath = os.path.join(MESH_DIR, atlas_name, 'mean_shapes', filename)\n",
    "        print('Saving mesh at', filepath)\n",
    "        save_mesh_stl(surround_isosurface_polydata_all_levels[level], filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "# Compute transform.\n",
    "moving_instance_volume = instance_volumes[i]\n",
    "aligner = Aligner({0: template_instance_wrt_templateCentroid}, \n",
    "                  {0: (moving_instance_volume, np.array((0,0,0)))}, \n",
    "                  labelIndexMap_m2f={0:0})\n",
    "aligner.set_centroid(centroid_m='structure_centroid', centroid_f='structure_centroid')\n",
    "aligner.compute_gradient(smooth_first=True)\n",
    "lr = .1\n",
    "_, _ = aligner.optimize(tf_type='rigid', \n",
    "                     history_len=100, \n",
    "                    max_iter_num=100 if structure in ['SC', 'IC'] else 10000,\n",
    "                     grad_computation_sample_number=None,\n",
    "                        full_lr=np.array([lr,lr,lr,0.1,0.1,0.1]),\n",
    "                       terminate_thresh_trans=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(aligner.Ts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(aligner.scores);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[  9.69838248e-01   7.41253856e-02   2.32205080e-01  -3.58975061e+01]\n",
    " [ -7.00849620e-02   9.97212129e-01  -2.56138103e-02  -3.87932318e+01]\n",
    " [ -2.33456356e-01   8.56716872e-03   9.72329540e-01  -1.27806610e+01]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transform instances.\n",
    "T = convert_transform_forms(aligner=aligner, out_form=(3,4), select_best='max_value')\n",
    "\n",
    "aligned_moving_instance_volume, aligned_moving_instance_origin_wrt_templateCentroid = \\\n",
    "transform_volume_v4((moving_instance_volume, (0,0,0)), transform=T,\n",
    "                    return_origin_instead_of_bbox=True)\n",
    "\n",
    "aligned_moving_instance_wrt_templateCentroid = (aligned_moving_instance_volume, aligned_moving_instance_origin_wrt_templateCentroid)        \n",
    "\n",
    "# Generate meshes for each instance.\n",
    "\n",
    "instance_mesh_wrt_templateCentroid_all_instances = [\n",
    "volume_to_polydata((v, o), num_simplify_iter=3, smooth=True)\n",
    "for v, o in \n",
    "[template_instance_wrt_templateCentroid] + [aligned_moving_instance_wrt_templateCentroid]]\n",
    "\n",
    "launch_vtk([actor_mesh(mesh, wireframe=True, color=np.array(high_contrast_colors[i+1])/255., opacity=1) \n",
    "    for i, mesh in enumerate([instance_mesh_wrt_templateCentroid_all_instances[0],\n",
    "                             instance_mesh_wrt_templateCentroid_all_instances[1]])], \n",
    "  background_color=(1,1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name_u in all_known_structures:\n",
    "for name_u in ['5N']:\n",
    "    fig, axes = plt.subplots(1, 5,squeeze=True, figsize=(20,2));\n",
    "    for i in range(1, 6):\n",
    "#         try:\n",
    "        scores = DataManager.load_alignment_results_v3( what='scoreHistory',\n",
    "      alignment_spec=dict(warp_setting=108, \n",
    "                          stack_f=dict(name='%s_instance0' % name_u, vol_type='annotationAsScore'),\n",
    "                         stack_m=dict(name='%s_instance%d' % (name_u, i), vol_type='annotationAsScore')),\n",
    "                 reg_root_dir=os.path.join(MESH_ROOTDIR, atlas_name, 'mean_shapes', 'instance_registration'))        \n",
    "        axes[i-1].plot(scores);\n",
    "        axes[i-1].set_title('%s_instance%d' % (name_u, i))\n",
    "#         except:\n",
    "#             pass\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name_u in all_known_structures:\n",
    "for name_u in ['12N']:\n",
    "    fig, axes = plt.subplots(1, 5,squeeze=True, figsize=(20,2));\n",
    "    for i in range(1, 6):\n",
    "        trajectory = load_alignment_results_v3(what='trajectory',\n",
    "                          alignment_spec=dict(warp_setting=108, \n",
    "                                              stack_f=dict(name='%s_instance0' % name_u, vol_type='annotationAsScore'),\n",
    "                                             stack_m=dict(name='%s_instance%d' % (name_u, i), vol_type='annotationAsScore')),\n",
    "                                     reg_root_dir=os.path.join(MESH_DIR, atlas_name, 'mean_shapes', 'instance_registration'))        \n",
    "        axes[i-1].plot(trajectory);\n",
    "        axes[i-1].set_title('%s_instance%d' % (name_u, i))\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name_u in all_known_structures:\n",
    "\n",
    "    # Load instance meshes.\n",
    "    \n",
    "    instance_meshes = []\n",
    "    for i in range(6):\n",
    "        m = load_data(DataManager.get_instance_mesh_filepath(atlas_name=atlas_name, structure=name_u, \n",
    "                                                         index=i, resolution='10um'))\n",
    "        if m is not None:\n",
    "            instance_meshes.append(m)\n",
    "\n",
    "    launch_vtk([actor_mesh(m, wireframe=True, \n",
    "                           color=np.array(high_contrast_colors[i+1])/255., \n",
    "                           opacity=1, wireframe_linewidth=3) \n",
    "        for i, m in enumerate(instance_meshes)], \n",
    "      background_color=(1,1,1))\n",
    "    \n",
    "    # Load average shape.\n",
    "    \n",
    "    vol = load_data(DataManager.get_mean_shape_filepath(atlas_name=atlas_name, structure=name_u, what='volume', resolution='10.0um'))\n",
    "    ori_wrt_meanShapeCentroid = load_data(DataManager.get_mean_shape_filepath(atlas_name=atlas_name, structure=name_u, what='origin_wrt_meanShapeCentroid', resolution='10.0um'))\n",
    "    \n",
    "    standard_shape_volume_actor = actor_volume(vol.astype(np.float32), \n",
    "                                               what='probability', \n",
    "                                               origin=ori_wrt_meanShapeCentroid, \n",
    "                                              c=(0,0,0))\n",
    "    \n",
    "    launch_vtk([standard_shape_volume_actor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine standard shapes with standard centroid locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_resolution = '10.0um'\n",
    "atlas_resolution_um = convert_resolution_string_to_um(atlas_resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nominal_centroids_wrt_canonicalAtlasSpace_um = load_data(DataManager.get_structure_mean_positions_filepath(atlas_name=atlas_name, resolution='1um'))\n",
    "nominal_centroids_wrt_canonicalAtlasSpace_10um = {s: c / atlas_resolution_um for s, c in nominal_centroids_wrt_canonicalAtlasSpace_um.iteritems()}\n",
    "\n",
    "mean_shapes_10um_wrt_stdShapeCentroid = {name_u: DataManager.load_mean_shape(atlas_name=atlas_name, structure=name_u, resolution=atlas_resolution) \n",
    "                    for name_u in all_known_structures_unsided_including_surround_200um}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_spec = dict(name='atlasV6', vol_type='score', resolution=atlas_resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: simplify this.\n",
    "\n",
    "# mean_shape_wrt_canonicalAtlasSpace_all_structures_10um = {}\n",
    "\n",
    "for name_u in all_known_structures:\n",
    "# for name_u in ['7N']:\n",
    "      \n",
    "#     mean_shape_10um, mean_shape_origin_wrt_stdShapeCentroid_10um = mean_shapes_10um_wrt_stdShapeCentroid[name_u]\n",
    "#     mean_shape_surround_10um, mean_shape_surround_origin_wrt_stdShapeCentroid_10um = mean_shapes_10um_wrt_stdShapeCentroid[convert_to_surround_name(name_u, margin='200um')]\n",
    "    \n",
    "    if name_u in singular_structures:\n",
    "                \n",
    "        for name in [name_u, convert_to_surround_name(name_u, margin='200um')]:\n",
    "            \n",
    "            mean_shape_wrt_canonicalAtlasSpace_10um = (mean_shapes_10um_wrt_stdShapeCentroid[name][0], \n",
    "                        mean_shapes_10um_wrt_stdShapeCentroid[name][1] + nominal_centroids_wrt_canonicalAtlasSpace_10um[name_u])\n",
    "            \n",
    "#             mean_shape_wrt_canonicalAtlasSpace_all_structures_10um[name] = mean_shape_wrt_canonicalAtlasSpace_10um\n",
    "\n",
    "            DataManager.save_original_volume(volume=mean_shape_wrt_canonicalAtlasSpace_10um, \n",
    "                                             stack_spec=atlas_spec, \n",
    "                                             structure=name, wrt='canonicalAtlasSpace')\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        left_name = convert_to_left_name(name_u)\n",
    "        left_surround_name = convert_to_surround_name(left_name, margin='200um')\n",
    "        right_name = convert_to_right_name(name_u)\n",
    "        right_surround_name = convert_to_surround_name(right_name, margin='200um')\n",
    "\n",
    "        left_mean_shape_wrt_canonicalAtlasSpace_10um = mirror_volume_v2(volume=mean_shapes_10um_wrt_stdShapeCentroid[name_u],\n",
    "             centroid_wrt_origin=-mean_shapes_10um_wrt_stdShapeCentroid[name_u][1],\n",
    "            new_centroid=nominal_centroids_wrt_canonicalAtlasSpace_10um[left_name])\n",
    "\n",
    "        DataManager.save_original_volume(volume=left_mean_shape_wrt_canonicalAtlasSpace_10um, \n",
    "                             stack_spec=atlas_spec, \n",
    "                             structure=left_name, wrt='canonicalAtlasSpace')\n",
    "\n",
    "        left_mean_shape_wrt_canonicalAtlasSpace_10um = mirror_volume_v2(\\\n",
    "            volume=mean_shapes_10um_wrt_stdShapeCentroid[convert_to_surround_name(name_u, margin='200um')][0],\n",
    "            centroid_wrt_origin=-mean_shapes_10um_wrt_stdShapeCentroid[convert_to_surround_name(name_u, margin='200um')][1],\n",
    "            new_centroid=nominal_centroids_wrt_canonicalAtlasSpace_10um[left_name])        \n",
    "        \n",
    "        DataManager.save_original_volume(volume=left_mean_shape_wrt_canonicalAtlasSpace_10um, \n",
    "                             stack_spec=atlas_spec, \n",
    "                             structure=left_surround_name, wrt='canonicalAtlasSpace')\n",
    "        \n",
    "        \n",
    "        right_mean_shape_wrt_canonicalAtlasSpace_10um = (mean_shapes_10um_wrt_stdShapeCentroid[name_u][0], \n",
    "        mean_shapes_10um_wrt_stdShapeCentroid[name_u][1] + nominal_centroids_wrt_canonicalAtlasSpace_10um[right_name])\n",
    "        \n",
    "        DataManager.save_original_volume(volume=right_mean_shape_wrt_canonicalAtlasSpace_10um, \n",
    "                                 stack_spec=atlas_spec, \n",
    "                                 structure=right_name, wrt='canonicalAtlasSpace')\n",
    "            \n",
    "        \n",
    "        \n",
    "        right_mean_shape_wrt_canonicalAtlasSpace_10um = (mean_shapes_10um_wrt_stdShapeCentroid[convert_to_surround_name(name_u, margin='200um')][0], \n",
    "        mean_shapes_10um_wrt_stdShapeCentroid[convert_to_surround_name(name_u, margin='200um')][1] + nominal_centroids_wrt_canonicalAtlasSpace_10um[right_name])\n",
    "        \n",
    "        DataManager.save_original_volume(volume=right_mean_shape_wrt_canonicalAtlasSpace_10um, \n",
    "                                 stack_spec=atlas_spec, \n",
    "                                 structure=right_surround_name, wrt='canonicalAtlasSpace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to vtk polydata for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name_s in all_known_structures_sided_including_surround_200um:\n",
    "# for name_s in ['7N_L', '7N_R']:\n",
    "\n",
    "    atlas_structure_wrt_canonicalAtlasSpace = \\\n",
    "    DataManager.load_original_volume_v2(stack_spec=atlas_spec, structure=name_s, bbox_wrt='canonicalAtlasSpace')\n",
    "\n",
    "    for surface_level in np.arange(0.1, 1.1, .1):\n",
    "        mean_shape_isosurface_polydata_wrt_canonicalAtlasSpace = \\\n",
    "        volume_to_polydata(volume=(atlas_structure_wrt_canonicalAtlasSpace[0] >= surface_level, atlas_structure_wrt_canonicalAtlasSpace[1]), \n",
    "                     num_simplify_iter=3, smooth=True, \n",
    "                     return_vertex_face_list=False)\n",
    "\n",
    "        save_data(mean_shape_isosurface_polydata_wrt_canonicalAtlasSpace, \n",
    "                  DataManager.get_mesh_filepath_v2(atlas_spec, structure=name_s, level=surface_level))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_shape_level05isosurface_polydata_wrt_canonicalAtlasSpace_all_structures = \\\n",
    "{name_s: load_data(DataManager.get_mesh_filepath_v2(atlas_spec, structure=name_s, level=0.5))\n",
    "for name_s in all_known_structures_sided}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_vtk([actor_mesh(v, wireframe=False, opacity=.5, color=name_unsided_to_color_float[convert_to_original_name(s)]) \n",
    "            for s, v in mean_shape_level05isosurface_polydata_wrt_canonicalAtlasSpace_all_structures.iteritems()] \\\n",
    "          + [actor_sphere([0,0,0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just use MD589's shell, until we find a way to average the outlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.conversion import *\n",
    "\n",
    "margin_um = 200\n",
    "margin_tb = margin_um / XY_PIXEL_DISTANCE_TB\n",
    "\n",
    "from scipy.ndimage.morphology import distance_transform_edt\n",
    "\n",
    "# for stack in ['MD594', 'MD585', 'MD593', 'MD592', 'MD590', 'MD591', 'MD595', 'MD598', 'MD602']:\n",
    "for stack in ['MD589']:\n",
    "    \n",
    "#     contours_valid_by_z = {}\n",
    "    contour_prob_maps_by_sec = {}\n",
    "    \n",
    "    for sec in metadata_cache['valid_sections'][stack]:\n",
    "                \n",
    "        m = DataManager.load_thumbnail_mask_v3(stack, prep_id=2, section=sec)\n",
    "        contours = find_contour_points(m, sample_every=1)[1]\n",
    "        contours_valid = [cnt[(cnt[:,0] >= 1) & (cnt[:,1] >= 1)] for cnt in contours]\n",
    "        \n",
    "#         z = np.mean(DataManager.convert_section_to_z(stack, sec, downsample=32, z_begin=0))\n",
    "#         contours_valid_by_z[z] = contours_valid[0]\n",
    "        \n",
    "        m2 = np.zeros_like(m, np.bool)\n",
    "        for cnt in contours_valid:\n",
    "            m2[cnt[:,1], cnt[:,0]] = 1\n",
    "        distance_to_contour = distance_transform_edt(~m2)\n",
    "        contour_prob_map = np.exp(-distance_to_contour**2/(2*margin_tb)**2)\n",
    "        contour_prob_map[contour_prob_map < 1e-2] = 0\n",
    "        contour_prob_maps_by_sec[sec] = contour_prob_map\n",
    "        \n",
    "outline_prob_volume_atlasResol, outline_prob_volume_origin_wrt_wholebrainXYcropped_atlasResol = \\\n",
    "images_to_volume_v2(images=contour_prob_maps_by_sec, spacing_um=20, \n",
    "                    in_resol_um=convert_resolution_string_to_um(resolution='down32', stack=stack_fixed),\n",
    "                    out_resol_um = atlas_resolution_um)\n",
    "                                                                    \n",
    "# outline_prob_volume_bbox (xm,xm,ym,ym) relative to cropped, (zm,zm) relative to uncropped.\n",
    "\n",
    "# crop_box = metadata_cache['cropbox']['MD589']\n",
    "alignedBrainstemCrop_cropbox_down32 = DataManager.load_cropbox_v2(stack=stack_fixed, prep_id='alignedBrainstemCrop')\n",
    "alignedBrainstemCrop_cropbox_atlasResol = alignedBrainstemCrop_cropbox_down32 * convert_resolution_string_to_um('down32', stack=stack_fixed) / atlas_resolution_um\n",
    "\n",
    "outline_prob_volume_origin_rel2fixedwholebrain_atlasResol = outline_prob_volume_origin_wrt_wholebrainXYcropped_atlasResol + (alignedBrainstemCrop_cropbox_atlasResol[0], alignedBrainstemCrop_cropbox_atlasResol[2], 0)\n",
    "\n",
    "display_volume_sections(outline_prob_volume, direction='z', ncols=5, cmap=plt.cm.gray, start_level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outline_prob_volume_origin_rel2canon_atlasResol = outline_prob_volume_origin_rel2fixedwholebrain_atlasResol - \\\n",
    "canonical_center_wrt_fixed_um/convert_resolution_string_to_um(resolution='10.0um')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shell_vol_origin_dict_rel2canon = {'shell': (outline_prob_volume_atlasResol, outline_prob_volume_origin_rel2canon_atlasResol)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Side task: compute the volumes of structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_resolution = '10.0um'\n",
    "atlas_resolution_um = 10.0\n",
    "atlas_spec = dict(name='atlasV7', vol_type='score', resolution=atlas_resolution)\n",
    "volumes = load_original_volume_all_known_structures_v3(atlas_spec, \n",
    "                           structures=all_known_structures_sided)\n",
    "\n",
    "volumes_mm3 = defaultdict(dict)\n",
    "for name_u in all_known_structures:\n",
    "    for level in np.arange(0, 1.1, .1):\n",
    "        volumes_mm3[name_u][level] = np.count_nonzero(volumes[convert_to_left_name(name_u)][0] > level) * 10.**3 / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame(volumes_mm3).to_csv('/home/yuncong/structure_volumes_mm3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_shape_level05surface_polydata_wrt_canonicalAtlasSpace_all_structures = \\\n",
    "DataManager.load_meshes_v2(atlas_spec, levels=.5, include_surround=True, \n",
    "                           structures=all_known_structures_sided)\n",
    "#                            structures=all_known_structures_sided + all_known_structures_sided_with_surround_200um)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_vtk([actor_mesh(p, wireframe=True) \n",
    "           for s, p in standard_shape_level05surface_polydata_wrt_canonicalAtlasSpace_all_structures.iteritems()] \\\n",
    "            + [actor_sphere((0,0,0), radius=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show multiple iso-surfaces\n",
    "\n",
    "standard_shape_level010surface_polydata_wrt_canonicalAtlasSpace_all_structures = \\\n",
    "DataManager.load_meshes_v2(atlas_spec, levels=.1, include_surround=True, \n",
    "                           structures=all_known_structures_sided)\n",
    "#                            structures=all_known_structures_sided + all_known_structures_sided_with_surround_200um)\n",
    "\n",
    "standard_shape_level090surface_polydata_wrt_canonicalAtlasSpace_all_structures = \\\n",
    "DataManager.load_meshes_v2(atlas_spec, levels=.9, include_surround=True, \n",
    "                           structures=all_known_structures_sided)\n",
    "#                            structures=all_known_structures_sided + all_known_structures_sided_with_surround_200um)\n",
    "\n",
    "launch_vtk([actor_mesh(p, wireframe=False, color=name_unsided_to_color_float[convert_to_unsided_label(s)], opacity=.2) \n",
    "           for s, p in standard_shape_level010surface_polydata_wrt_canonicalAtlasSpace_all_structures.iteritems()] \\\n",
    "           + [actor_mesh(p, wireframe=False, color=name_unsided_to_color_float[convert_to_unsided_label(s)], opacity=.1) \n",
    "           for s, p in standard_shape_level090surface_polydata_wrt_canonicalAtlasSpace_all_structures.iteritems()] \\\n",
    "            + [actor_sphere((0,0,0), radius=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load shell\n",
    "\n",
    "stack_fixed = 'MD589'\n",
    "shell_polydata_rel2fixedWholebrain = DataManager.load_mesh_v2(brain_spec={'name':stack_fixed, \n",
    "                                                                    'vol_type':'annotationAsScore',\n",
    "                                                                   'resolution':'10.0um'}, \n",
    "                                                        structure='shell')\n",
    "\n",
    "shell_polydata_rel2canonicalAtlasSpace = move_polydata(shell_polydata_rel2fixedWholebrain,\n",
    "                                                       -canonical_center_wrt_fixed_um / convert_resolution_string_to_um(resolution='10.0um'))\n",
    "\n",
    "shell_actor_rel2canon = actor_mesh(shell_polydata_rel2fixedWholebrain, (1,1,1), opacity=.15, \n",
    "                              wireframe=False, origin=-canonical_center_wrt_fixed_um / convert_resolution_string_to_um(resolution='10.0um'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(shell_polydata_rel2canonicalAtlasSpace, \n",
    "          DataManager.get_mesh_filepath_v2(atlas_spec, structure='shell', level=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_vtk([actor_mesh(p, wireframe=False, color=name_unsided_to_color_float[convert_to_unsided_label(s)], opacity=.2) \n",
    "           for s, p in standard_shape_level010surface_polydata_wrt_canonicalAtlasSpace_all_structures.iteritems()] \\\n",
    "           + [actor_mesh(p, wireframe=False, color=name_unsided_to_color_float[convert_to_unsided_label(s)], opacity=.1) \n",
    "           for s, p in standard_shape_level090surface_polydata_wrt_canonicalAtlasSpace_all_structures.iteritems()] \\\n",
    "            + [actor_sphere((0,0,0), radius=1)]\\\n",
    "#           +[shell_actor_rel2canon] \\\n",
    "           +[actor_mesh(shell_polydata_rel2canonicalAtlasSpace, (1,1,1), opacity=.15, \n",
    "                              wireframe=False)]\n",
    "#           +[actor_volume(shell_vol_origin_dict_rel2canon['shell'][0].astype(np.float32), \n",
    "#                          what='probability', origin=shell_vol_origin_dict_rel2canon['shell'][1])]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atlas_volume, structure_to_label, label_to_structure = \\\n",
    "# DataManager.load_original_volume_all_known_structures(stack=atlas_name, sided=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol, origin_rel2canon = structure_vol_origin_dicts_rel2canon['7N_L']\n",
    "\n",
    "one_structure_volume_actor_rel2canon = actor_volume(vol.astype(np.float32), what='score', \n",
    "                                              origin=origin_rel2canon,\n",
    "                                                    auxdata=0.8*(vol>0.1).astype(np.float32),\n",
    "                                              c=np.array(name_unsided_to_color['7N'])/255.)\n",
    "#                                             c=np.array((1,0,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_vtk([] \\\n",
    "    + structure_mesh_actors_rel2canon \\\n",
    "#     + [one_structure_volume_actor_rel2canon] \\\n",
    "#     + [shell_volume_actor_rel2canon] \\\n",
    "#     + structure_mesh_surround_actors_rel2canon \\\n",
    "    + [shell_actor_rel2canon] \\\n",
    "    + [actor_sphere((0,0,0), radius=1)], \n",
    "           init_angle='sagittal', \n",
    "    background_color=(1,1,1),\n",
    "depth_peeling=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
