{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import ast\n",
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:41641/v/a9f2fd351afbd6e4de33dd749c7bcd331fb31082/\n"
     ]
    }
   ],
   "source": [
    "import neuroglancer\n",
    "viewer = neuroglancer.Viewer()\n",
    "print(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting dklab@192.168.1.12:3306\n"
     ]
    }
   ],
   "source": [
    "HOME = os.path.expanduser(\"~\")\n",
    "sys.path.append(os.path.join(HOME, 'programming', 'pipeline_utility'))\n",
    "from utilities.file_location import FileLocationManager\n",
    "from utilities.sqlcontroller import SqlController\n",
    "from utilities.alignment_utility import SCALING_FACTOR, load_consecutive_section_transform, create_warp_transforms, \\\n",
    "    transform_create_alignment\n",
    "from utilities.contour_utilities import get_dense_coordinates, get_contours_from_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [00:06<00:00, 10.27it/s]\n"
     ]
    }
   ],
   "source": [
    "animal = 'MD589'\n",
    "sqlController = SqlController(animal)\n",
    "fileLocationManager = FileLocationManager(animal)\n",
    "width = sqlController.scan_run.width\n",
    "height = sqlController.scan_run.height\n",
    "width = int(width * SCALING_FACTOR)\n",
    "height = int(height * SCALING_FACTOR)\n",
    "aligned_shape = np.array((width, height))\n",
    "THUMBNAIL_PATH = os.path.join(fileLocationManager.prep, 'CH1', 'thumbnail')\n",
    "THUMBNAILS = sorted(os.listdir(THUMBNAIL_PATH))\n",
    "num_section = len(THUMBNAILS)\n",
    "structure_dict = sqlController.get_structures_dict()\n",
    "\n",
    "\n",
    "CSV_PATH = '/net/birdstore/Active_Atlas_Data/data_root/atlas_data/foundation_brain_annotations'\n",
    "csvfile = os.path.join(CSV_PATH, f'{animal}_annotation.csv')\n",
    "hand_annotations = pd.read_csv(csvfile)\n",
    "hand_annotations['vertices'] = hand_annotations['vertices'] \\\n",
    "    .apply(lambda x: x.replace(' ', ','))\\\n",
    "    .apply(lambda x: x.replace('\\n',','))\\\n",
    "    .apply(lambda x: x.replace(',]',']'))\\\n",
    "    .apply(lambda x: x.replace(',,', ','))\\\n",
    "    .apply(lambda x: x.replace(',,', ','))\\\n",
    "    .apply(lambda x: x.replace(',,', ',')).apply(lambda x: x.replace(',,', ','))\n",
    "hand_annotations['vertices'] = hand_annotations['vertices'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "structures = list(hand_annotations['name'].unique())\n",
    "section_structure_vertices = defaultdict(dict)\n",
    "for structure in tqdm(structures):\n",
    "    contour_annotations, first_sec, last_sec = get_contours_from_annotations(animal, structure, hand_annotations, densify=4)\n",
    "    for section in contour_annotations:\n",
    "        section_structure_vertices[section][structure] = contour_annotations[section][structure][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 447/447 [00:05<00:00, 85.94it/s] \n"
     ]
    }
   ],
   "source": [
    "##### Reproduce create_clean transform\n",
    "section_offset = {}\n",
    "for file_name in tqdm(THUMBNAILS):\n",
    "    filepath = os.path.join(THUMBNAIL_PATH, file_name)\n",
    "    img = io.imread(filepath)\n",
    "    section = int(file_name.split('.')[0])\n",
    "    section_offset[section] = (aligned_shape - img.shape[:2][::-1]) // 2\n",
    "\n",
    "\n",
    "##### Reproduce create_alignment transform\n",
    "CLEANED = os.path.join(fileLocationManager.prep, 'CH1', 'thumbnail_cleaned')\n",
    "\n",
    "image_name_list = sorted(os.listdir(CLEANED))\n",
    "anchor_idx = len(image_name_list) // 2\n",
    "transformation_to_previous_sec = {}\n",
    "\n",
    "for i in range(1, len(image_name_list)):\n",
    "    fixed_fn = os.path.splitext(image_name_list[i - 1])[0]\n",
    "    moving_fn = os.path.splitext(image_name_list[i])[0]\n",
    "    transformation_to_previous_sec[i] = load_consecutive_section_transform(animal, moving_fn, fixed_fn)\n",
    "\n",
    "transformation_to_anchor_sec = {}\n",
    "# Converts every transformation\n",
    "for moving_idx in range(len(image_name_list)):\n",
    "    if moving_idx == anchor_idx:\n",
    "        transformation_to_anchor_sec[image_name_list[moving_idx]] = np.eye(3)\n",
    "    elif moving_idx < anchor_idx:\n",
    "        T_composed = np.eye(3)\n",
    "        for i in range(anchor_idx, moving_idx, -1):\n",
    "            T_composed = np.dot(np.linalg.inv(transformation_to_previous_sec[i]), T_composed)\n",
    "        transformation_to_anchor_sec[image_name_list[moving_idx]] = T_composed\n",
    "    else:\n",
    "        T_composed = np.eye(3)\n",
    "        for i in range(anchor_idx + 1, moving_idx + 1):\n",
    "            T_composed = np.dot(transformation_to_previous_sec[i], T_composed)\n",
    "        transformation_to_anchor_sec[image_name_list[moving_idx]] = T_composed\n",
    "\n",
    "\n",
    "warp_transforms = create_warp_transforms(animal, transformation_to_anchor_sec, 'thumbnail', 'thumbnail')\n",
    "ordered_transforms = sorted(warp_transforms.items())\n",
    "section_transform = {}\n",
    "\n",
    "for section, transform in ordered_transforms:\n",
    "    section_num = int(section.split('.')[0])\n",
    "    transform = np.linalg.inv(transform)\n",
    "    section_transform[section_num] = transform\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Alignment of annotation coordinates\n",
    "# Note, for missing sections, neuroglancer is minus one the section retrieved here\n",
    "# Litao, check this code, most of it is yours but i added the defaultdict to fill up the points\n",
    "keys = [k for k in structure_dict.keys()]\n",
    "#Litao, this missing_sections will need to be manually built up from Beth's spreadhsheet\n",
    "missing_sections = {k:[117] for k in keys}\n",
    "fill_sections = defaultdict(dict)\n",
    "other_structures = set()\n",
    "volume = np.zeros((aligned_shape[1], aligned_shape[0], num_section), dtype=np.uint8)\n",
    "for section in section_structure_vertices:\n",
    "    template = np.zeros((aligned_shape[1], aligned_shape[0]), dtype=np.uint8)\n",
    "    for structure in section_structure_vertices[section]:\n",
    "        points = np.array(section_structure_vertices[section][structure])\n",
    "        points = points // 32\n",
    "        points = points + section_offset[section]  # create_clean offset\n",
    "        points = transform_create_alignment(points, section_transform[section])  # create_alignment transform\n",
    "        points = points.astype(np.int32)\n",
    "        \n",
    "        try:\n",
    "            missing_list = missing_sections[structure]\n",
    "        except:\n",
    "            missing_list = []\n",
    "            \n",
    "        if section in missing_list:\n",
    "            fill_sections[structure][section] = points\n",
    "            \n",
    "        try:\n",
    "            #color = colors[structure.upper()]\n",
    "            color = structure_dict[structure][1] # structure dict returns a list of [description, color]\n",
    "            # for each key\n",
    "        except:\n",
    "            color = 255\n",
    "            other_structures.add(structure)\n",
    "\n",
    "        cv2.polylines(template, [points], True, color, 2, lineType=cv2.LINE_AA)\n",
    "    volume[:, :, section - 1] = template\n",
    "\n",
    "# fill up missing sections\n",
    "template = np.zeros((aligned_shape[1], aligned_shape[0]), dtype=np.uint8)\n",
    "for structure,v in fill_sections.items():\n",
    "    color = structure_dict[structure][1]\n",
    "    for section, points in v.items():\n",
    "        cv2.polylines(template, [points], True, color, 2, lineType=cv2.LINE_AA)\n",
    "        volume[:, :, section] = template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:41641/v/a9f2fd351afbd6e4de33dd749c7bcd331fb31082/\n"
     ]
    }
   ],
   "source": [
    "volume = np.swapaxes(volume, 0, 1)\n",
    "all_volume_layer = neuroglancer.SegmentationLayer(\n",
    "    source = neuroglancer.LocalVolume(\n",
    "        data=volume, \n",
    "        dimensions=neuroglancer.CoordinateSpace(names=['x', 'y', 'z'], units='nm', scales=[14464, 14464, 20000]), \n",
    "        voxel_offset=(0, 0, 0)\n",
    "    ),\n",
    ")\n",
    "\n",
    "with viewer.txn() as s:\n",
    "    s.layers.clear()\n",
    "    s.layers['all'] = all_volume_layer\n",
    "print(viewer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
