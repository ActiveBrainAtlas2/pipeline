{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install these\n",
    "#https://pymicro.readthedocs.io/projects/pymicro/en/latest/cookbook/pointset_registration.html\n",
    "from pymicro.view.vol_utils import compute_affine_transform\n",
    "#https://pypi.org/project/affine6p/\n",
    "import affine6p\n",
    "#https://github.com/jewettaij/superpose3d\n",
    "from superpose3d import Superpose3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = os.path.expanduser(\"~\")\n",
    "DIR = os.path.join(HOME, 'programming/pipeline_utility')\n",
    "sys.path.append(DIR)\n",
    "from utilities.contour_utilities import get_contours_from_annotations, add_structure_to_neuroglancer, \\\n",
    "    create_full_volume, get_structure_colors\n",
    "from utilities.sqlcontroller import SqlController\n",
    "animal = 'MD589'\n",
    "sqlController = SqlController(animal)\n",
    "\n",
    "CSV_PATH = '/net/birdstore/Active_Atlas_Data/data_root/atlas_data/foundation_brain_annotations'\n",
    "csvfile = os.path.join(CSV_PATH, 'MD589_annotation.csv')\n",
    "hand_annotations = pd.read_csv(csvfile)\n",
    "hand_annotations.head()\n",
    "hand_annotations['vertices'] = hand_annotations['vertices'] \\\n",
    "    .apply(lambda x: x.replace(' ', ','))\\\n",
    "    .apply(lambda x: x.replace('\\n',','))\\\n",
    "    .apply(lambda x: x.replace(',]',']'))\\\n",
    "    .apply(lambda x: x.replace(',,', ','))\\\n",
    "    .apply(lambda x: x.replace(',,', ','))\\\n",
    "    .apply(lambda x: x.replace(',,', ',')).apply(lambda x: x.replace(',,', ','))\n",
    "\n",
    "hand_annotations['vertices'] = hand_annotations['vertices'].apply(lambda x: ast.literal_eval(x))\n",
    "structures = ['DC', 'LC','SC', '5N', '7n']\n",
    "# SC is the only singular structure\n",
    "df = hand_annotations[['name', 'section', 'side', 'vertices']].copy()\n",
    "df = df.loc[df['name'].isin(structures)]\n",
    "df = df.reset_index()\n",
    "df = df.sort_values(by=['name', 'section'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the 5 structures Beth suggested for getting\n",
    "# enough that were spread out.\n",
    "structures = ['DC', 'LC','SC', '5N', '7n']\n",
    "centers = {}\n",
    "section_structure_vertices = defaultdict(dict)\n",
    "SC = df.loc[(df['name'] == \"SC\")]\n",
    "first_section = SC['section'].min()\n",
    "last_section = SC['section'].max()\n",
    "midsection = int(round(((last_section - first_section) / 2) + first_section))\n",
    "point_array = SC['vertices'].loc[SC['section'] == midsection].values\n",
    "section_structure_vertices[midsection]['SC'] = point_array[0]\n",
    "cx, cy = np.mean(point_array[0], axis=0)    \n",
    "centers['SC'] = [int(round(cx)), int(round(cy)), int(round(midsection))]\n",
    "\n",
    "structures.remove('SC')\n",
    "for structure in structures:\n",
    "    df_tmp = df.loc[(df['name'] == structure) & (df['side'] == \"L\")]\n",
    "    first_section = df_tmp['section'].min()\n",
    "    last_section = df_tmp['section'].max()\n",
    "    midsection = int(round(((last_section - first_section) / 2) + first_section))\n",
    "    structure_name = structure + \"_L\"\n",
    "    point_array = df_tmp['vertices'].loc[df_tmp['section'] == midsection].values\n",
    "    section_structure_vertices[midsection][structure_name] = point_array[0]\n",
    "    cx, cy = np.mean(point_array[0], axis=0)    \n",
    "    centers[structure_name] = [int(round(cx)), int(round(cy)), int(round(midsection))]\n",
    "    \n",
    "    df_tmp = df.loc[(df['name'] == structure) & (df['side'] == \"R\")]\n",
    "    first_section = df_tmp['section'].min()\n",
    "    last_section = df_tmp['section'].max()\n",
    "    midsection = int(round(((last_section - first_section) / 2) + first_section))\n",
    "    structure_name = structure + \"_R\"\n",
    "    point_array = df_tmp['vertices'].loc[df_tmp['section'] == midsection].values\n",
    "    section_structure_vertices[midsection][structure_name] = point_array[0]\n",
    "    cx, cy = np.mean(point_array[0], axis=0)    \n",
    "    centers[structure_name] = [int(round(cx)), int(round(cy)), int(round(midsection))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 0.5\n",
    "thickness = 1\n",
    "colors = {}\n",
    "colors['SC'] = (255,0,255)\n",
    "\n",
    "colors['DC_L'] = (0,0,0)\n",
    "colors['LC_L'] = (255,0,0)\n",
    "colors['SC_L'] = (255,0,255)\n",
    "colors['5N_L'] = (0,255,255)\n",
    "colors['7n_L'] = (100,10,255)\n",
    "colors['DC_R'] = (0,0,0)\n",
    "colors['LC_R'] = (255,0,0)\n",
    "colors['SC_R'] = (255,0,255)\n",
    "colors['5N_R'] = (0,255,255)\n",
    "colors['7n_R'] = (100,10,255)\n",
    "# create a fake random distance away from the original structures\n",
    "rand_offset = np.random.randint(75,150)\n",
    "offsets = {}\n",
    "section_images = {}\n",
    "points = {}\n",
    "SCALE = 32\n",
    "PATH = f'/net/birdstore/Active_Atlas_Data/data_root/pipeline_data/{animal}/preps/CH1'\n",
    "thumbnail_dir = os.path.join(PATH, 'thumbnail')\n",
    "files = sorted(os.listdir(thumbnail_dir))\n",
    "for file_name in tqdm(files):\n",
    "    filepath = os.path.join(thumbnail_dir, file_name)\n",
    "    img = cv2.imread(filepath)\n",
    "    section = int(file_name.split('.')[0])\n",
    "    \n",
    "    for structure in section_structure_vertices[section]:\n",
    "        pts = section_structure_vertices[section][structure]\n",
    "        points = np.array(pts, dtype=np.int32)        \n",
    "        points = points // SCALE\n",
    "        \n",
    "        points_diff = np.rint(points + rand_offset)\n",
    "        points_diff = points_diff.astype(np.int32)\n",
    "        cxoff, cyoff = np.mean(points_diff, axis=0)\n",
    "        offsets[structure] = [int(round(cxoff*SCALE)), int(round(cyoff*SCALE)), section]\n",
    "        \n",
    "        cv2.polylines(img, [points_diff], isClosed=True, color=(0,0,0), thickness=5)\n",
    "        cx = centers[structure][0] // SCALE\n",
    "        cy = centers[structure][1] // SCALE\n",
    "        \n",
    "        cv2.circle(img, (cx,cy), 10, (0,0,0), -1)\n",
    "            \n",
    "        cv2.polylines(img, [points], isClosed=True, color=colors[structure], thickness=2)\n",
    "        cv2.putText(img, structure, (cx,cy), font,\n",
    "                    fontScale, colors[structure], thickness, cv2.LINE_AA)\n",
    "            \n",
    "    section_images[section] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this shows the real structure, it's center of mass and a fake offsetted structure\n",
    "structure_midpoints = [134,160,177,180,220,268,284,298,330]\n",
    "section = structure_midpoints[0]\n",
    "fig=plt.figure(figsize=(26,18), dpi= 100, facecolor='w', edgecolor='k')\n",
    "plt.imshow(section_images[section], cmap=\"cool\")\n",
    "plt.title('{} section:{}'.format(animal, section))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = np.array(list(centers.values()), dtype=np.float32)\n",
    "fitted = np.array(list(offsets.values()), dtype=np.float32)\n",
    "# create a fake structure with a center of mass at:\n",
    "other_structure = (25000,15000,200)\n",
    "print(origin.shape, fitted.shape, other_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_centroid = np.mean(origin, axis=0)\n",
    "fitted_centroid = np.mean(fitted, axis=0)\n",
    "print(origin_centroid, fitted_centroid, other_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import affine6p\n",
    "trans = affine6p.estimate(origin, fitted)\n",
    "translated = trans.transform(other_structure)\n",
    "print('translated',translated)\n",
    "rotated = trans.rotate(other_structure)\n",
    "print('rotated',rotated)\n",
    "both = trans.rotate(translated)\n",
    "print('both',both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSD, R, T, c = Superpose3D(origin, fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(other_structure)\n",
    "origin_centroid + np.dot(R, other_structure - fitted_centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the affine transform from the point set\n",
    "translation, transformation = compute_affine_transform(origin, fitted)\n",
    "invt = np.linalg.inv(transformation)\n",
    "offset = -np.dot(invt, translation)\n",
    "print(other_structure, origin_centroid + np.dot(transformation, other_structure - fitted_centroid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = 'brgmkbrgmk'\n",
    "new_points = np.empty_like(origin)\n",
    "for i in range(len(origin)):\n",
    "    print('fitted',type(fitted[i]))\n",
    "    new_points[i] = origin_centroid + np.dot(transformation, fitted[i] - fitted_centroid)\n",
    "    print('new points', new_points[i])\n",
    "    print('point %d will move to (%3.1f, %3.1f, %3.1f) to be compared with (%3.1f, %3.1f, %3.1f)' % (\n",
    "    i, new_points[i, 0], new_points[i, 1], new_points[i, 2], origin[i, 0], origin[i, 1], origin[i, 2]))\n",
    "    plt.plot(new_points[i, 0], new_points[i, 1], 'x', color=colors[i], markersize=12,\n",
    "             label='new points' if i == 0 else '')\n",
    "plt.legend(numpoints=1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_points"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
